{"cells":[{"cell_type":"code","source":["!pip install -q keras==2.8.0\n","!pip install -q tensorflow==2.8.0"],"metadata":{"id":"_MTm1AOZ6O67"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"VVCYqVQsFX3H"},"outputs":[],"source":["from sklearn.metrics import recall_score, precision_score, f1_score, roc_auc_score,accuracy_score\n","from sklearn.ensemble import RandomForestClassifier,RandomForestRegressor\n","from sklearn.model_selection import train_test_split\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.neighbors import KNeighborsClassifier\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.tree import DecisionTreeClassifier\n","from multiprocessing.pool import ThreadPool\n","from sklearn.naive_bayes import GaussianNB\n","from collections import deque, defaultdict\n","from imblearn.over_sampling import SMOTE\n","from warnings import filterwarnings\n","from xgboost import XGBClassifier\n","from scipy.special import softmax\n","import matplotlib.pyplot as plt\n","from tqdm.notebook import tqdm\n","from keras import backend as K\n","from typing import Callable\n","import tensorflow as tf\n","from sklearn import svm\n","from typing import List\n","import seaborn as sns\n","import pandas as pd\n","import numpy as np\n","import requests\n","import logging\n","import pickle\n","import random\n","import keras\n","import copy\n","import json\n","import sys\n","import os\n","import gc\n","\n","logging.getLogger(\"tensorflow\").setLevel(logging.ERROR)\n","sns.set(rc = {'figure.figsize':(22,12)}, style=\"whitegrid\")\n","filterwarnings('ignore')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":48065,"status":"ok","timestamp":1692698484719,"user":{"displayName":"Muawiya Al danaf","userId":"16999440410141197833"},"user_tz":-180},"id":"5Wy2RLh8SiIz","outputId":"daddc264-650b-4f27-8fd7-4d5d35307ebc"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"eD-d-Bzc2F3s"},"outputs":[],"source":["data_path = '/content/drive/My Drive/Colab Notebooks/Muawiya/Genetic Programming Combiner with DFS/data'\n","code_path = '/content/drive/My Drive/Colab Notebooks/Muawiya/Genetic Programming Combiner with DFS/Codes/Shared Codes'\n","results_path = '/content/drive/My Drive/Colab Notebooks/Muawiya/Genetic Programming Combiner with DFS/results'\n","feature_selection_results = '/content/drive/My Drive/Colab Notebooks/Muawiya/Genetic Programming Combiner with DFS/feature_selection_results'"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"leRBlofFVGLw"},"outputs":[],"source":["sys.path.insert(0,code_path)\n","from genetic_programming import SymbolicRegressor\n","from binirizer import CustomLabelBinirizer\n","from ensemble import Ensemble, Classifier\n","from oselm import OSELMClassifier,set_use_know\n","from DynamicFeatureSelection import dynamic_feature_selection\n","from SharedFunctions import prepare_data,train_and_test,feature_evolving,save_pickle,load_pickle,save_object,load_object,generate_new_samples"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"nH3sC4sDZhk3"},"outputs":[],"source":["# import matplotlib.pyplot as plt\n","# import numpy as np\n","# epsilon=0.97\n","# epsilon_decay=0.040\n","# # min_epsilon = 0.01\n","# episod = 200\n","# e = []\n","# for i in range(episod):\n","#     epsilon -= epsilon *  epsilon_decay\n","#     e.append(epsilon)\n","# print(epsilon)\n","# x = [ i for i in range(episod)]\n","# plt.plot(range(episod), e,label=f'epsilon decay policy')\n","# plt.xlabel('steps')\n","# plt.ylabel('epsilon')\n","# plt.savefig('0-25.svg', format='svg')\n","# plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"OwP_3Tj_FXz0"},"outputs":[],"source":["def epsilon_greedy(expected_reward, epsilon=0.97) -> int:\n","    \"\"\"\n","    expected_reward: list of expected rewards for each possible action\n","    epsilon: .\n","    \"\"\"\n","    if np.random.rand() <= epsilon:\n","        return np.random.choice(list(range(len(expected_reward))))\n","    else:\n","        return np.argmax(expected_reward)\n","PolicyFunction  = Callable[[np.ndarray, float], int]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"FCL570_PFXxS"},"outputs":[],"source":["LEARNING_RATE = 0.001\n","def create_model(input_dim):\n","    K.clear_session()\n","    model = keras.models.Sequential()\n","    model.add(keras.layers.Input(shape=(input_dim,)))\n","    model.add(keras.layers.Dense(32, kernel_initializer='he_uniform', activation='relu'))\n","    model.add(keras.layers.Dense(16, kernel_initializer='he_uniform', activation='relu'))\n","    model.add(keras.layers.Dense(2,))\n","    model.compile(loss='mse', optimizer='adam')\n","    return model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"JgYQ8fao3YFJ"},"outputs":[],"source":["class Agents:\n","    def __init__(self, evaluation_network,number_of_featuer, buffer_size: int = 800):\n","\n","        self.evaluation_network = evaluation_network\n","        self.target_network = copy.deepcopy(self.evaluation_network)\n","        self.buffer_size = buffer_size\n","        self.fitted = False\n","        self.number_of_featuer = number_of_featuer\n","        self.reply_buffer = deque(maxlen=self.buffer_size)\n","        self.contrbution = np.random.rand()\n","\n","    def make_action(self, curr_state: np.ndarray, policy_function: PolicyFunction, epsilon) -> int:\n","        if self.fitted:\n","            q_values = self.evaluation_network.predict(curr_state.reshape(-1, self.number_of_featuer),verbose=0)\n","            action = policy_function(q_values, epsilon)\n","        else:\n","            action = policy_function([0, 1], 1)\n","        return action\n","\n","    def update_target_network(self):\n","        self.target_network = copy.deepcopy(self.evaluation_network)\n","        return"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"XQSWchnH7oA8"},"outputs":[],"source":["class AgentsSoftmax(Agents):\n","    agent_count = 0\n","    def __init__(self, evaluation_network,number_of_featuer, buffer_size=800):\n","        self.agent_id = AgentsSoftmax.agent_count\n","        AgentsSoftmax.agent_count += 1\n","        super().__init__(evaluation_network,number_of_featuer, buffer_size)\n","\n","    def update_evaluation_network(self, batch_size=32, epochs=5, discount_factor=0.995):\n","        batch = random.sample(self.reply_buffer, batch_size)\n","        Q1, actions, Q2, rewards = [], [], [], []\n","        for transition in batch:\n","            Q1.append(transition[0])\n","            actions.append(transition[1])\n","            Q2.append(transition[2])\n","            rewards.append(transition[3])\n","        X_train = np.array(Q1).reshape(-1, self.number_of_featuer)\n","        expected_reward = self.evaluation_network.predict(np.array(Q1).reshape(-1, self.number_of_featuer),verbose=0)\n","        Q2 = self.target_network.predict(np.array(Q2).reshape(-1, self.number_of_featuer),verbose=0)\n","        for i, act in enumerate(actions[:-1]):\n","            expected_reward[i, act] = rewards[i] + (discount_factor * np.argmax(Q2[i]))\n","        y_train = expected_reward.copy()\n","        change_frequency = 0\n","        for state, next_state, reward, next_reward in zip(X_train[:-1], X_train[1:], rewards[: -1], rewards[1:]):\n","            if np.abs(state[self.agent_id] - next_state[self.agent_id]) == 1:\n","                self.contrbution += np.abs(reward - next_reward)\n","                change_frequency += 1\n","        self.contrbution = 0 if change_frequency==0 else self.contrbution/change_frequency\n","        self.evaluation_network.fit(X_train, y_train, epochs=epochs, verbose=0)\n","        self.fitted = True\n","        return"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Fn_yLK3h3YFK"},"outputs":[],"source":["class AgentsRegression(Agents):\n","    agent_count = 0\n","    def __init__(self, evaluation_network,number_of_featuer, buffer_size=800):\n","        self.agent_id = AgentsRegression.agent_count\n","        AgentsRegression.agent_count += 1\n","        super().__init__(evaluation_network,number_of_featuer, buffer_size)\n","\n","    def update_evaluation_network(self, batch_size=32, epochs=5, discount_factor=0.995):\n","        batch = random.sample(self.reply_buffer, batch_size)\n","        Q1, actions, Q2, rewards = [], [], [], []\n","        for transition in batch:\n","            Q1.append(transition[0])\n","            actions.append(transition[1])\n","            Q2.append(transition[2])\n","            rewards.append(transition[3])\n","        X_train = np.array(Q1).reshape(-1, self.number_of_featuer)\n","\n","        expected_reward = self.evaluation_network.predict(np.array(Q1).reshape(-1, self.number_of_featuer),verbose=0)\n","        Q2 = self.target_network.predict(np.array(Q2).reshape(-1, self.number_of_featuer),verbose=0)\n","        for i, act in enumerate(actions[:-1]):\n","            expected_reward[i, act] = rewards[i] + (discount_factor * np.argmax(Q2[i]))\n","        y_train = expected_reward.copy()\n","        self.evaluation_network.fit(X_train, y_train, epochs=epochs, verbose=0)\n","        self.fitted = True\n","        return"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3BzhumpF3YFL"},"outputs":[],"source":["class AgentsAverage(Agents):\n","    agent_count = 0\n","    def __init__(self, evaluation_network,number_of_featuer, buffer_size=800):\n","        self.agent_id = AgentsAverage.agent_count\n","        AgentsAverage.agent_count += 1\n","        super().__init__(evaluation_network,number_of_featuer, buffer_size)\n","\n","    def update_evaluation_network(self, batch_size=32, epochs=5, discount_factor=0.995):\n","        batch = random.sample(self.reply_buffer, batch_size)\n","        Q1, actions, Q2, rewards = [], [], [], []\n","        for transition in batch:\n","            Q1.append(transition[0])\n","            actions.append(transition[1])\n","            Q2.append(transition[2])\n","            rewards.append(transition[3])\n","        X_train = np.array(Q1).reshape(-1, self.number_of_featuer)\n","\n","        expected_reward = self.evaluation_network.predict(np.array(Q1).reshape(-1, self.number_of_featuer),verbose=0)\n","        Q2 = self.target_network.predict(np.array(Q2).reshape(-1, self.number_of_featuer),verbose=0)\n","        for i, act in enumerate(actions[:-1]):\n","            expected_reward[i, act] = rewards[i] + (discount_factor * np.argmax(Q2[i]))\n","        y_train = expected_reward.copy()\n","        WINDOW_SIZE = 4\n","        X_train_ = np.zeros((X_train.shape[0] // WINDOW_SIZE, X_train.shape[1]))\n","        y_train_ = []\n","        j = 0\n","        for i in range(0, batch_size, WINDOW_SIZE):\n","            window_of_states = X_train[i: i + WINDOW_SIZE].sum(axis=0) / WINDOW_SIZE\n","            window_of_rewards = sum(rewards[i: i + WINDOW_SIZE])\n","            r = window_of_rewards * window_of_states[self.agent_id]\n","            X_train_[j, :] = np.around(window_of_states)\n","            if window_of_states[self.agent_id] == 0:\n","                if window_of_rewards > 0.6:\n","                    r = window_of_rewards\n","                else:\n","                    r = window_of_rewards / WINDOW_SIZE\n","            y_train_.append(r)\n","            j += 1\n","        X_train = X_train_\n","        y_train = np.array(y_train_)\n","        self.evaluation_network.fit(X_train, y_train, epochs=epochs, verbose=0)\n","        self.fitted = True\n","        return"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"H0rnKcjH3YFM"},"outputs":[],"source":["class AgentsSingle(Agents):\n","    agent_count = 0\n","    def __init__(self, evaluation_network,number_of_featuer, buffer_size=800):\n","        self.agent_id = AgentsSingle.agent_count\n","        AgentsSingle.agent_count += 1\n","        super().__init__(evaluation_network,number_of_featuer, buffer_size)\n","\n","    def update_evaluation_network(self, batch_size=32, epochs=5, discount_factor=0.995):\n","        batch = random.sample(self.reply_buffer, batch_size)\n","        Q1, actions, Q2, rewards = [], [], [], []\n","        for transition in batch:\n","            Q1.append(transition[0])\n","            actions.append(transition[1])\n","            Q2.append(transition[2])\n","            rewards.append(transition[3])\n","        X_train = np.array(Q1).reshape(-1, self.number_of_featuer)\n","        expected_reward = self.evaluation_network.predict(np.array(Q1).reshape(-1, self.number_of_featuer),verbose=0)\n","        Q2 = self.target_network.predict(np.array(Q2).reshape(-1, self.number_of_featuer),verbose=0)\n","        for i, act in enumerate(actions[:-1]):\n","            expected_reward[i, act] = rewards[i] + (discount_factor * np.argmax(Q2[i]))\n","        y_train = expected_reward.copy()\n","        self.evaluation_network.fit(X_train, y_train, epochs=epochs, verbose=0)\n","        self.fitted = True\n","        return"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"52gC4qqJ_KWJ"},"outputs":[],"source":["def replay_buffer_decentralize(self, batch_size, model):\n","        minibatch = random.sample(self.memory, batch_size)\n","        target = 0\n","        for exploitation, state, action, reward, next_state in minibatch:\n","            target = reward\n","            if next_state is not None:\n","                next_state = np.array(next_state).reshape([1, np.array(next_state).shape[0]])\n","                logit_value = model.predict(next_state, verbose=0)[0]\n","                target = reward + self.gamma * np.amax(logit_value)\n","            state = np.array(state).reshape([1, np.array(state).shape[0]])\n","            target_f = model.predict(state, verbose=0)\n","            target_f[0][action] = target\n","            model.fit(state, target_f, epochs=1, verbose=0)\n","        if self.epsilon > self.min_epsilon:\n","            self.epsilon -= self.epsilon * self.epsilon_decay\n","        return target"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7qPhNaatTSLY"},"outputs":[],"source":["def generate_oselm_models(number_of_hidden_neurons, apply_model_replacement=False):\n","    models= [OSELMClassifier(number_of_hidden_neurons, 'relu', binarizer=CustomLabelBinirizer(), random_state=42),\n","             OSELMClassifier(number_of_hidden_neurons, 'relu', binarizer=CustomLabelBinirizer(), random_state=42),\n","             OSELMClassifier(number_of_hidden_neurons, 'relu', binarizer=CustomLabelBinirizer(), random_state=42),\n","             OSELMClassifier(number_of_hidden_neurons, 'relu', binarizer=CustomLabelBinirizer(), random_state=42),\n","             ]\n","\n","    ensemble = Ensemble(classifiers=models, program=genetic_programming(), apply_model_replacement=apply_model_replacement)\n","    return ensemble\n","\n","def generate_ml_models(number_of_hidden_neurons, apply_model_replacement=False):\n","    models = [\n","              KNeighborsClassifier(5),\n","              KNeighborsClassifier(5),\n","              LogisticRegression(),\n","              LogisticRegression(),\n","              GaussianNB(),\n","              GaussianNB(),\n","              GaussianNB(),\n","              ]\n","    ensemble = Ensemble(classifiers=models, program=genetic_programming(), apply_model_replacement=apply_model_replacement)\n","    return ensemble"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"EUqGh0r23YFM"},"outputs":[],"source":["# test set percentage\n","TESTSIZE=0.2\n","def get_reward(X,Y ,subset_features,apply_model_replacement=True):\n","\n","    if sum(subset_features)==0:return -10\n","    global TESTSIZE\n","    subset_features = np.where(np.array(subset_features) == 1)[0]\n","    if subset_features.shape[0] == 0:return -5\n","\n","    X_train, X_test, y_train, y_test = train_test_split(X, Y, random_state=42, test_size=TESTSIZE)\n","    X_train, X_test = X_train[:,subset_features], X_test[:,subset_features]\n","\n","    OSELM_Classifier = OSELMClassifier(X.shape[1]*3 // 2, 'relu', binarizer=CustomLabelBinirizer(), random_state=42)\n","\n","    OSELM_Classifier.fit(X_train, y_train)\n","\n","    y_pred1 = OSELM_Classifier.predict(X_test)\n","\n","    # acc1 = accuracy_score(y_test, y_pred1)\n","    reward = f1_score(y_test, y_pred1)\n","\n","    return reward"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"IAdaPMPSe2Kl"},"outputs":[],"source":["def reward_strategy(time_step: int, accuracy: float, accuracy_history: list, subset_features: list, error_rate: float,\n","                    beta: float = 0.99):\n","\n","    if sum(subset_features) == len(subset_features):\n","        return -5,-1\n","\n","    elif sum(subset_features) == 0:\n","        return -10,-1\n","\n","    elif accuracy > max(accuracy_history):\n","        return accuracy,1\n","\n","    elif accuracy < max(accuracy_history):\n","        return -accuracy,-1\n","\n","    else:\n","        return -1 * (beta * error_rate + ((1 - beta) * (sum(subset_features) / len(subset_features)))),-1"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7MfHt0ifMBYc"},"outputs":[],"source":["def save_object(obj, filename,path):\n","    \"\"\"\n","    _ INPUT (obj) THE OBJECT WE NEED SAVW IT (filename) THE NAME OF OBJECT\n","    \"\"\"\n","    filename = os.path.join(path,filename)\n","    with open(filename+\".pkl\", 'wb') as outp:\n","        pickle.dump(obj, outp, pickle.HIGHEST_PROTOCOL)\n","    outp.close()\n","def load_object(filename,path):\n","    \"\"\"\n","    _ INPUT THE NAME OF OBJECT WE NEED LOAD IT\n","    \"\"\"\n","    filename = os.path.join(path,filename)\n","    with open(filename+\".pkl\", 'rb') as outp:\n","        loaded_object = pickle.load(outp)\n","    outp.close()\n","    return loaded_object"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"PubHgDBA3YFO"},"outputs":[],"source":["def softmax_distrbution(agents):\n","    contrbutions = []\n","    for agent in agents:\n","        contrbutions.append(agent.contrbution)\n","    return softmax(contrbutions)\n","\n","def random_forest_distrbution(X_train,Y_train,num_of_agents, num_of_samples=1000):\n","    X,y = [],[]\n","    for i in range(num_of_samples):\n","        features_space = np.random.choice([0, 1], size=(num_of_agents,)).tolist()\n","        accuracy = get_reward(X_train,Y_train, features_space)\n","        X.append(features_space)\n","        y.append(accuracy)\n","    X = np.array(X)\n","    y = np.array(y)\n","    rf = RandomForestRegressor(n_estimators=15)\n","    rf.fit(X, y)\n","    return rf.feature_importances_.tolist()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"aLiW-JOFzR1N"},"outputs":[],"source":["def prepare_data(csv_filename, target_column_name='class'):\n","    df = pd.read_csv(csv_filename)\n","    df = df.iloc[:80000, :]\n","    column_names = df.columns.tolist()\n","    if target_column_name not in column_names:\n","        target_column_name = column_names[-1]\n","    unique_vlaues = sorted(df[target_column_name].unique().tolist())\n","    df[target_column_name] = df[target_column_name].apply(lambda x: 0 if x == unique_vlaues[0] else 1)\n","    df[target_column_name] = df[target_column_name].astype('int')\n","    num_of_columns = len(column_names)\n","    df.columns = list(range(num_of_columns))\n","    return df"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9A0KUfP6Sogv"},"outputs":[],"source":["def feature_selection(algo_type, agents, X, Y, eposide=200):\n","    epsilon=0.97\n","    epsilon_decay=0.040\n","    NUMBER_OF_AGENTS = X.shape[1]\n","    best_features = []\n","    features_space = np.random.choice([0, 1], size=(NUMBER_OF_AGENTS,)).tolist()\n","    contrbutions = []\n","    if algo_type == 'random_forest':\n","        contrbutions = random_forest_distrbution(X,Y,NUMBER_OF_AGENTS)\n","    elif algo_type in ['single_agent', 'average']:\n","        contrbutions = [1] * NUMBER_OF_AGENTS\n","    for i in tqdm(range(eposide)):\n","        rewards = [0]\n","        next_feature_space = []\n","        if algo_type == 'softmax':\n","            contrbutions = softmax_distrbution(agents)\n","        for t in range(0, NUMBER_OF_AGENTS):\n","            action = agents[t].make_action(np.array(features_space.copy()), epsilon_greedy, epsilon)\n","            next_feature_space.append(action)\n","            if algo_type == 'single_agent':\n","                features_space[t] = action\n","        reward_as_accuracy = get_reward(X,Y, next_feature_space)\n","        reward_at_time_t,best = reward_strategy(t, reward_as_accuracy, rewards, next_feature_space, 1 - reward_as_accuracy)\n","        if best>0:\n","          best_features = next_feature_space\n","        rewards.append(reward_as_accuracy)\n","        total_reward = reward_at_time_t\n","        transition = []\n","        for t in range(0, NUMBER_OF_AGENTS):\n","            transition.clear()\n","            feature_space_copy = features_space.copy()\n","            transition.append(feature_space_copy)\n","            action = next_feature_space[t]\n","            transition.append(action)\n","            transition.append(next_feature_space)\n","            transition.append(total_reward * contrbutions[t])\n","            agents[t].reply_buffer.append(transition)\n","            if len(agents[t].reply_buffer) > 32 and i % 32 == 0:\n","                agents[t].update_evaluation_network()\n","        if i % 64 == 0:\n","            for agent in agents:\n","                if agent.fitted:\n","                    agent.update_target_network()\n","        epsilon -= epsilon *  epsilon_decay\n","        features_space = next_feature_space\n","    return best_features if len(best_features)>0 else next_feature_space"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"AS5FDN_E0bPJ"},"outputs":[],"source":["def generate_new_samples(buffer, y_values, n=500, y_col='label'):\n","    if not y_col in buffer.columns.tolist():\n","      y_col = buffer.columns.tolist()[-1]\n","    if y_values.sum() == 0:\n","       return buffer[buffer[y_col] == 1].sample(n, random_state=41)[:, :-1].values, np.array([1] * n)\n","    else:\n","      return buffer[buffer[y_col] == 0].sample(n,random_state=41)[:, :-1].values, np.array([0] * n)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"fssDIs2hfmJT"},"outputs":[],"source":["def save_pickle(obj, file_name):\n","  with open(file_name, 'wb') as f:\n","    pickle.dump(obj, f)\n","def load_pickle(file_name):\n","  with open(file_name, 'rb') as f:\n","    d = pickle.load(f)\n","  return d"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3DaNb5bJ3YFP"},"outputs":[],"source":["from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score, classification_report\n","\n","def model_evaluation(X_train, X_test, y_train, y_test, selected_features):\n","    subset_features = np.where(np.array(selected_features) == 1)[0]\n","    if subset_features.shape[0] == 0:return 0\n","    X_train, X_test = X_train[:,subset_features], X_test[:,subset_features]\n","    model = OSELMClassifier(X_train.shape[1]*3 // 2, 'relu', binarizer=CustomLabelBinirizer(), random_state=42)\n","    model.fit(X_train, y_train)\n","    y_pred = model.predict(X_test)\n","    f1 = f1_score(y_test, y_pred)\n","    recall = recall_score(y_test, y_pred)\n","    precision = precision_score(y_test, y_pred)\n","    accuracy = accuracy_score(y_test, y_pred)\n","    report = classification_report(y_test, y_pred)\n","    print(f1,recall,precision,accuracy)\n","    return f1,recall,precision,accuracy,y_pred"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"N0DK-w4NOqX4"},"outputs":[],"source":["def dynamic_feature_selection(chunk_X, chunk_Y,X_test,y_test,save_path,algorithm_type=['softmax','average','single_agent','random_forest'],chunk_number=0):\n","  AgentsSoftmax.agent_count,AgentsAverage.agent_count,AgentsSingle.agent_count,AgentsRegression.agent_count = 0,0,0,0\n","  softmax_agents,average_agents,single_agent_agents,random_forest_agents,result,over_all=[],[],[],[],[],[]\n","  NUM_OF_FEATURES = chunk_X.shape[1]\n","  for i in range(NUM_OF_FEATURES):\n","\n","    if 'random_forest' in algorithm_type:\n","      random_forest_agents.append(AgentsSoftmax(create_model(NUM_OF_FEATURES),NUM_OF_FEATURES))\n","    if 'average' in algorithm_type:\n","      average_agents.append(AgentsAverage(create_model(NUM_OF_FEATURES),NUM_OF_FEATURES))\n","    if 'single_agent' in algorithm_type:\n","      single_agent_agents.append(AgentsSingle(create_model(NUM_OF_FEATURES),NUM_OF_FEATURES))\n","    if 'softmax' in algorithm_type:\n","      softmax_agents.append(AgentsRegression(create_model(NUM_OF_FEATURES),NUM_OF_FEATURES))\n","\n","\n","  softmax_results,average_results,single_agent_results,random_forest_results,voting_results = results_dic(save_path,chunk_number)\n","\n","  if 'softmax' in algorithm_type:\n","    softmax_result = feature_selection('softmax', softmax_agents,chunk_X, chunk_Y)\n","    f1, recall ,precision ,accuracy ,y_predicte = model_evaluation(chunk_X, X_test, chunk_Y, y_test, softmax_result)\n","    over_all.append(f1)\n","    save_object(softmax_result, \"softmax_mask_\"+str(chunk_number),save_path)\n","    softmax_results[\"f1\"].append(f1)\n","    softmax_results[\"recall\"].append(recall)\n","    softmax_results[\"precision\"].append(precision)\n","    softmax_results[\"accuracy\"].append(accuracy)\n","    softmax_results[\"y_predicte\"].append(y_predicte)\n","    save_object(softmax_results, \"softmax_results\",save_path)\n","    gc.collect()\n","\n","\n","  if 'average' in algorithm_type:\n","    average_result = feature_selection('average', average_agents,chunk_X, chunk_Y)\n","    f1, recall ,precision ,accuracy ,y_predicte = model_evaluation(chunk_X, X_test, chunk_Y, y_test, average_result)\n","    over_all.append(f1)\n","    save_object(average_result, \"average_mask_\"+str(chunk_number),save_path)\n","    average_results[\"f1\"].append(f1)\n","    average_results[\"recall\"].append(recall)\n","    average_results[\"precision\"].append(precision)\n","    average_results[\"accuracy\"].append(accuracy)\n","    average_results[\"y_predicte\"].append(y_predicte)\n","    save_object(average_results, \"average_results\",save_path)\n","    gc.collect()\n","\n","  if 'single_agent' in algorithm_type:\n","    single_agent_result = feature_selection('single_agent', single_agent_agents,chunk_X, chunk_Y)\n","    f1, recall ,precision  ,accuracy ,y_predicte = model_evaluation(chunk_X, X_test, chunk_Y, y_test, single_agent_result)\n","    over_all.append(f1)\n","    save_object(single_agent_result, \"single_agent_mask_\"+str(chunk_number),save_path)\n","    single_agent_results[\"f1\"].append(f1)\n","    single_agent_results[\"recall\"].append(recall)\n","    single_agent_results[\"precision\"].append(precision)\n","    single_agent_results[\"accuracy\"].append(accuracy)\n","    single_agent_results[\"y_predicte\"].append(y_predicte)\n","    save_object(single_agent_results, \"single_agent_results\",save_path)\n","    gc.collect()\n","\n","  if 'random_forest' in algorithm_type:\n","    random_forest_result = feature_selection('random_forest', random_forest_agents,chunk_X, chunk_Y)\n","    f1, recall ,precision  ,accuracy ,y_predicte = model_evaluation(chunk_X, X_test, chunk_Y, y_test, random_forest_result)\n","    over_all.append(f1)\n","\n","    save_object(random_forest_result, \"random_forest_mask_\"+str(chunk_number),save_path)\n","    random_forest_results[\"f1\"].append(f1)\n","    random_forest_results[\"recall\"].append(recall)\n","    random_forest_results[\"precision\"].append(precision)\n","    random_forest_results[\"accuracy\"].append(accuracy)\n","    random_forest_results[\"y_predicte\"].append(y_predicte)\n","    save_object(random_forest_results, \"random_forest_results\",save_path)\n","    gc.collect()\n","\n","  softmax_result=load_object(\"softmax_mask_\"+str(chunk_number),save_path)\n","  average_result=load_object(\"average_mask_\"+str(chunk_number),save_path)\n","  single_agent_result=load_object(\"single_agent_mask_\"+str(chunk_number),save_path)\n","  random_forest_result=load_object(\"random_forest_mask_\"+str(chunk_number),save_path)\n","\n","  for softmax,average,single,random in zip(softmax_result,average_result,single_agent_result,random_forest_result):\n","    sum_votes = sum([softmax,average,single,random])\n","    if sum_votes > (len(algorithm_type) // 2):result.append(1)\n","    elif sum_votes == (len(algorithm_type) // 2):\n","      rand = np.random.uniform(low=0,high=1)\n","      if rand >0.5:result.append(1)\n","      else:result.append(0)\n","    else:result.append(0)\n","\n","  f1, recall ,precision  ,accuracy ,y_predicte = model_evaluation(chunk_X, X_test, chunk_Y, y_test, result)\n","  over_all.append(f1)\n","  save_object(result, \"voting_mask_\"+str(chunk_number),save_path)\n","  voting_results[\"f1\"].append(f1)\n","  voting_results[\"recall\"].append(recall)\n","  voting_results[\"precision\"].append(precision)\n","  voting_results[\"accuracy\"].append(accuracy)\n","  voting_results[\"y_predicte\"].append(y_predicte)\n","  save_object(voting_results, \"voting_results\",save_path)\n","  gc.collect()\n","\n","  re_all = [softmax_result,average_result,single_agent_result,random_forest_result,result]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"F6oMmLR79rSM"},"outputs":[],"source":["from sklearn.ensemble import RandomForestClassifier\n","from sklearn.feature_selection import SelectFromModel\n","def random_forest_feature_selection(X, y):\n","    \"\"\"\n","    return best feature from X using random forest\n","    \"\"\"\n","    sel = SelectFromModel(RandomForestClassifier(n_estimators = 4))\n","    sel.fit(X, y)\n","    return sel.get_support()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2O-Uy8opyJjv"},"outputs":[],"source":["def main(f_name,train_size=0.80 , result_save_path=\"\",ChunkNumber=0,feature_selection_type='',algorithm_type=['softmax','average','single_agent','random_forest']):\n","\n","  datasets = {}\n","  d = prepare_data(f_name)\n","  d = d.sample(frac=1, random_state=42)\n","  buffer = d.sample(n=5000)\n","  d.reset_index(inplace=True)\n","  d.replace([np.inf], 0, inplace=True)\n","  datasets[f_name.split('/')[-1]] = d\n","  results = {}\n","\n","  for key in tqdm(datasets.keys()):\n","      drift_location = {}\n","      results[key] = {'model_result': []}\n","      data = datasets[key].values\n","      X, Y = data[:, 0:-1], data[:, -1].astype('int')\n","      chunks_features = np.array_split(X, 10)\n","      chunks_labels = np.array_split(Y, 10)\n","      print(\"===================== dataset : {} ======================\".format(key))\n","      for CN,chunk_X, chunk_Y in tqdm(zip([*range(len(chunks_labels))],chunks_features, chunks_labels)):\n","          try:\n","            chunk_X, chunk_Y = SMOTE().fit_resample(chunk_X, chunk_Y)\n","          except:\n","            if chunk_Y.sum() in [0, 1]:\n","              new_samples, new_labels = generate_new_samples(buffer, chunk_Y)\n","              chunk_X = np.concatenate((chunk_X, new_samples))\n","              chunk_Y = np.concatenate((chunk_Y, new_labels))\n","          gc.collect()\n","          X_train, X_test, y_train, y_test = train_test_split(chunk_X, chunk_Y, random_state=42, train_size=train_size)\n","          # if feature_selection_type == \"feature_evolving\":\n","          #   unselected_feautres = feature_evolving(evolving_matrix=evolving_matrix)\n","            # chunk_X = np.delete(chunk_X, unselected_feautres, 1)\n","\n","          dynamic_feature_selection(chunk_X=X_train, chunk_Y=y_train,X_test=X_test,y_test=y_test,save_path=result_save_path,chunk_number=CN,algorithm_type=algorithm_type)\n","          RF_selected = random_forest_feature_selection(X_train, y_train)\n","          f1, recall ,precision  ,accuracy ,y_predicte = model_evaluation(chunk_X, X_test, chunk_Y, y_test, RF_selected)\n","          print(\"CHUNK NUMBER \",CN,\"DONE\")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":10,"status":"ok","timestamp":1692698489074,"user":{"displayName":"Muawiya Al danaf","userId":"16999440410141197833"},"user_tz":-180},"id":"DnzKMN2W3YFP","outputId":"8d041615-9945-45f5-c193-9c9fdd2abfec"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["['/content/drive/My Drive/Colab Notebooks/Muawiya/Genetic Programming Combiner with DFS/data/kddcup99_csv.csv',\n"," '/content/drive/My Drive/Colab Notebooks/Muawiya/Genetic Programming Combiner with DFS/data/ISCX2012.csv',\n"," '/content/drive/My Drive/Colab Notebooks/Muawiya/Genetic Programming Combiner with DFS/data/CSE-CIC2018.csv',\n"," '/content/drive/My Drive/Colab Notebooks/Muawiya/Genetic Programming Combiner with DFS/data/CICIDS2017.csv',\n"," '/content/drive/My Drive/Colab Notebooks/Muawiya/Genetic Programming Combiner with DFS/data/7recurrentDrift.csv',\n"," '/content/drive/My Drive/Colab Notebooks/Muawiya/Genetic Programming Combiner with DFS/data/blip.csv',\n"," '/content/drive/My Drive/Colab Notebooks/Muawiya/Genetic Programming Combiner with DFS/data/incrementalDrift.csv',\n"," '/content/drive/My Drive/Colab Notebooks/Muawiya/Genetic Programming Combiner with DFS/data/7gradualDrift.csv',\n"," '/content/drive/My Drive/Colab Notebooks/Muawiya/Genetic Programming Combiner with DFS/data/7suddenDrift.csv']"]},"metadata":{},"execution_count":30}],"source":["filenames = ['kddcup99_csv.csv','ISCX2012.csv','CSE-CIC2018.csv','CICIDS2017.csv','7recurrentDrift.csv', 'blip.csv', 'incrementalDrift.csv',\n","             '7gradualDrift.csv', '7suddenDrift.csv']\n","filenames = list(map(lambda x: os.path.join(data_path, x), filenames))\n","filenames"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"iC4Go5kD3YFQ"},"outputs":[],"source":["def results_dic(path,chunk_number=0):\n","  if chunk_number == 0 :\n","    softmax_results = {\"f1\":[],\"recall\":[],\"precision\":[],\"accuracy\":[],\"y_predicte\":[]}\n","    average_results = {\"f1\":[],\"recall\":[],\"precision\":[],\"accuracy\":[],\"y_predicte\":[]}\n","    single_agent_results = {\"f1\":[],\"recall\":[],\"precision\":[],\"accuracy\":[],\"y_predicte\":[]}\n","    random_forest_results = {\"f1\":[],\"recall\":[],\"precision\":[],\"accuracy\":[],\"y_predicte\":[]}\n","    voting_results = {\"f1\":[],\"recall\":[],\"precision\":[],\"accuracy\":[],\"y_predicte\":[]}\n","  else:\n","    softmax_results = load_object('softmax_results',path)\n","    average_results = load_object('average_results',path)\n","    single_agent_results = load_object('single_agent_results',path)\n","    random_forest_results = load_object('random_forest_results',path)\n","    voting_results = load_object('voting_results',path)\n","  return softmax_results,average_results,single_agent_results,random_forest_results,voting_results"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"FeMX-96XIx-K"},"outputs":[],"source":["data_name = ['kddcup99','ISCX2012','CSE-CIC2018','CICIDS2017','7recurrentDrift', 'blip', 'incrementalDrift','7gradualDrift', '7suddenDrift']"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"E89f4vOyv_Dw"},"outputs":[],"source":["# # data_name = ['kddcup99','ISCX2012','CSE-CIC2018','CICIDS2017','7recurrentDrift', 'blip', 'incrementalDrift','7gradualDrift', '7suddenDrift']\n","# # for f_name,d_name in zip(filenames,data_name):\n","# #   path = os.path.join(feature_selection_results_evolving,d_name)\n","# #   os.makedirs(path, exist_ok=True)\n","# #   main(f_name, result_save_path=path,feature_selection_type=\"feature_evolving\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"66Zhjy3fY-2o"},"outputs":[],"source":["# DATA_NUMBER=0\n","# ChunkNumber=0\n","# f_name,d_name = filenames[DATA_NUMBER],data_name[DATA_NUMBER]\n","# path = os.path.join(feature_selection_results,d_name)\n","# os.makedirs(path, exist_ok=True)\n","# main(f_name, result_save_path=path,ChunkNumber=ChunkNumber)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"66B5KQSCY-2v"},"outputs":[],"source":["# DATA_NUMBER=1\n","# ChunkNumber=0\n","# f_name,d_name = filenames[DATA_NUMBER],data_name[DATA_NUMBER]\n","# path = os.path.join(feature_selection_results,d_name)\n","# os.makedirs(path, exist_ok=True)\n","# main(f_name, result_save_path=path,feature_selection_type=\"feature_evolving\",ChunkNumber=ChunkNumber)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Y2DjLb4wY-2v"},"outputs":[],"source":["# DATA_NUMBER=2\n","# ChunkNumber=0\n","# f_name,d_name = filenames[DATA_NUMBER],data_name[DATA_NUMBER]\n","# path = os.path.join(feature_selection_results,d_name)\n","# os.makedirs(path, exist_ok=True)\n","# main(f_name, result_save_path=path,feature_selection_type=\"feature_evolving\",ChunkNumber=ChunkNumber)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"uHGQKuLLY-2v"},"outputs":[],"source":["# DATA_NUMBER=3\n","# ChunkNumber=6\n","# f_name,d_name = filenames[DATA_NUMBER],data_name[DATA_NUMBER]\n","# path = os.path.join(feature_selection_results,d_name)\n","# os.makedirs(path, exist_ok=True)\n","# main(f_name, result_save_path=path,feature_selection_type=\"feature_evolving\",ChunkNumber=ChunkNumber)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"dZdCfn3EY-2v"},"outputs":[],"source":["# DATA_NUMBER=4\n","# ChunkNumber=0\n","# f_name,d_name = filenames[DATA_NUMBER],data_name[DATA_NUMBER]\n","# path = os.path.join(feature_selection_results,d_name)\n","# os.makedirs(path, exist_ok=True)\n","# main(f_name, result_save_path=path,feature_selection_type=\"feature_evolving\",ChunkNumber=ChunkNumber)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"hvkwmkwvY-2w"},"outputs":[],"source":["# DATA_NUMBER=5\n","# ChunkNumber=0\n","# f_name,d_name = filenames[DATA_NUMBER],data_name[DATA_NUMBER]\n","# path = os.path.join(feature_selection_results,d_name)\n","# os.makedirs(path, exist_ok=True)\n","# main(f_name, result_save_path=path,feature_selection_type=\"feature_evolving\",ChunkNumber=ChunkNumber)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"WxHMjTw_Y-2w"},"outputs":[],"source":["# DATA_NUMBER=6\n","# ChunkNumber=0\n","# f_name,d_name = filenames[DATA_NUMBER],data_name[DATA_NUMBER]\n","# path = os.path.join(feature_selection_results,d_name)\n","# os.makedirs(path, exist_ok=True)\n","# main(f_name, result_save_path=path,feature_selection_type=\"feature_evolving\",ChunkNumber=ChunkNumber,)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2ergZkpeY-2w"},"outputs":[],"source":["# DATA_NUMBER=7\n","# ChunkNumber=0\n","# f_name,d_name = filenames[DATA_NUMBER],data_name[DATA_NUMBER]\n","# path = os.path.join(feature_selection_results,d_name)\n","# os.makedirs(path, exist_ok=True)\n","# main(f_name, result_save_path=path,feature_selection_type=\"feature_evolving\",ChunkNumber=ChunkNumber)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"JLi4xzffY-2w"},"outputs":[],"source":["# DATA_NUMBER=8\n","# ChunkNumber=0\n","# f_name,d_name = filenames[DATA_NUMBER],data_name[DATA_NUMBER]\n","# path = os.path.join(feature_selection_results,d_name)\n","# os.makedirs(path, exist_ok=True)\n","# main(f_name, result_save_path=path,feature_selection_type=\"feature_evolving\",ChunkNumber=ChunkNumber)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6we8oSDIY-2w"},"outputs":[],"source":[]}],"metadata":{"accelerator":"GPU","colab":{"machine_shape":"hm","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.5"}},"nbformat":4,"nbformat_minor":0}