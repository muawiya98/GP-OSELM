{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["!pip install -q scikit-multiflow"],"metadata":{"id":"0IOVBrvhoAGV","executionInfo":{"status":"ok","timestamp":1695726466499,"user_tz":-180,"elapsed":51768,"user":{"displayName":"Muawiya Al danaf","userId":"16999440410141197833"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"7cb2c6d2-216c-4abf-aa77-f8ca2933e9b3"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/450.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m81.9/450.6 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m450.6/450.6 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m450.6/450.6 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Building wheel for scikit-multiflow (setup.py) ... \u001b[?25l\u001b[?25hdone\n"]}]},{"cell_type":"code","execution_count":2,"metadata":{"id":"maCUVDVx0i4C","executionInfo":{"status":"ok","timestamp":1695726474006,"user_tz":-180,"elapsed":7511,"user":{"displayName":"Muawiya Al danaf","userId":"16999440410141197833"}}},"outputs":[],"source":["from skmultiflow.drift_detection import ADWIN, DDM\n","from sklearn.metrics import recall_score, precision_score, f1_score, roc_auc_score,accuracy_score\n","from sklearn.ensemble import RandomForestClassifier,RandomForestRegressor\n","from sklearn.model_selection import train_test_split\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.neighbors import KNeighborsClassifier\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.tree import DecisionTreeClassifier\n","from collections import deque, defaultdict\n","from imblearn.over_sampling import SMOTE\n","import matplotlib.ticker as mticker\n","from warnings import filterwarnings\n","from xgboost import XGBClassifier\n","from scipy.special import softmax\n","import matplotlib.pyplot as plt\n","from tqdm.notebook import tqdm\n","from keras import backend as K\n","from typing import Callable\n","import tensorflow as tf\n","from sklearn import svm\n","from typing import List\n","import seaborn as sns\n","import pandas as pd\n","import numpy as np\n","import requests\n","import pickle\n","import random\n","import keras\n","import copy\n","import json\n","import sys\n","import os\n","import gc\n","sns.set(rc = {'figure.figsize':(22,12)}, style=\"whitegrid\")"]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"id":"Y5ZRBTmc0rOZ","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1695707749362,"user_tz":-180,"elapsed":21554,"user":{"displayName":"Muawiya Al danaf","userId":"16999440410141197833"}},"outputId":"567771e9-cf18-4788-c58c-837e4d0c810a"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["data_path = '/content/drive/My Drive/Colab Notebooks/Muawiya/Genetic Programming Combiner with DFS/data'\n","code_path = '/content/drive/My Drive/Colab Notebooks/Muawiya/Genetic Programming Combiner with DFS/Codes/Shared Codes'\n","results_path = '/content/drive/My Drive/Colab Notebooks/Muawiya/Genetic Programming Combiner with DFS/results'\n","feature_selection_results = '/content/drive/My Drive/Colab Notebooks/Muawiya/Genetic Programming Combiner with DFS/feature_selection_results'\n","DriftLocation = '/content/drive/My Drive/Colab Notebooks/Muawiya/Genetic Programming Combiner with DFS/Drift Location'"],"metadata":{"id":"pQdfybE6RGFf","executionInfo":{"status":"ok","timestamp":1695707778911,"user_tz":-180,"elapsed":2747,"user":{"displayName":"Muawiya Al danaf","userId":"16999440410141197833"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["sys.path.insert(0,code_path)\n","from genetic_programming import SymbolicRegressor,SymbolicClassifier\n","from binirizer import CustomLabelBinirizer\n","from ensemble import Ensemble, Classifier\n","from oselm import OSELMClassifier,set_use_know\n","from DynamicFeatureSelection import dynamic_feature_selection"],"metadata":{"id":"dD9lh-_6i4TV","executionInfo":{"status":"ok","timestamp":1695707790854,"user_tz":-180,"elapsed":2626,"user":{"displayName":"Muawiya Al danaf","userId":"16999440410141197833"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["def save_object(obj, filename,path):\n","    \"\"\"\n","    _ INPUT (obj) THE OBJECT WE NEED SAVW IT (filename) THE NAME OF OBJECT\n","    \"\"\"\n","    filename = os.path.join(path,filename)\n","    with open(filename+\".pkl\", 'wb') as outp:\n","        pickle.dump(obj, outp, pickle.HIGHEST_PROTOCOL)\n","    outp.close()\n","def load_object(filename,path):\n","    \"\"\"\n","    _ INPUT THE NAME OF OBJECT WE NEED LOAD IT\n","    \"\"\"\n","    filename = os.path.join(path,filename)\n","    with open(filename+\".pkl\", 'rb') as outp:\n","        loaded_object = pickle.load(outp)\n","    outp.close()\n","    return loaded_object"],"metadata":{"id":"mnIouTdY0rTc","executionInfo":{"status":"ok","timestamp":1695707837121,"user_tz":-180,"elapsed":2,"user":{"displayName":"Muawiya Al danaf","userId":"16999440410141197833"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":["def prepare_data(csv_filename, target_column_name='class'):\n","    # read csv file\n","    df = pd.read_csv(csv_filename)\n","    df = df.iloc[:80000, :]\n","    column_names = df.columns.tolist()\n","    if target_column_name not in column_names:\n","        target_column_name = column_names[-1]\n","    # get unique value in target column\n","    unique_vlaues = sorted(df[target_column_name].unique().tolist())\n","    df[target_column_name] = df[target_column_name].apply(lambda x: 0 if x == unique_vlaues[0] else 1)\n","    df[target_column_name] = df[target_column_name].astype('int')\n","    # rename the column of the dataframe\n","    num_of_columns = len(column_names)\n","    df.columns = list(range(num_of_columns))\n","    return df"],"metadata":{"id":"LnBlERgaicJv","executionInfo":{"status":"ok","timestamp":1695707838680,"user_tz":-180,"elapsed":2,"user":{"displayName":"Muawiya Al danaf","userId":"16999440410141197833"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","source":["def genetic_programming():\n","    return SymbolicRegressor(population_size=10,\n","            generations=5, stopping_criteria=0.85,\n","            p_crossover=0.7, p_subtree_mutation=0.1,\n","            p_hoist_mutation=0.05, p_point_mutation=0.1,\n","            max_samples=0.7, verbose=0,\n","            parsimony_coefficient=1e-4, random_state=42,\n","            function_set=['avg2', 'avg3', 'avg5','median3', 'median5', 'maximum2', 'maximum3', 'maximum5'],\n","            metric='f1-score')"],"metadata":{"id":"pw4NMJKXkT5d","executionInfo":{"status":"ok","timestamp":1695707841976,"user_tz":-180,"elapsed":3,"user":{"displayName":"Muawiya Al danaf","userId":"16999440410141197833"}}},"execution_count":8,"outputs":[]},{"cell_type":"code","source":["def generate_oselm_models(number_of_hidden_neurons, apply_model_replacement=False):\n","    models= [OSELMClassifier(number_of_hidden_neurons, 'relu', binarizer=CustomLabelBinirizer(), random_state=42),\n","             OSELMClassifier(number_of_hidden_neurons, 'relu', binarizer=CustomLabelBinirizer(), random_state=42),\n","             OSELMClassifier(number_of_hidden_neurons, 'relu', binarizer=CustomLabelBinirizer(), random_state=42),\n","             OSELMClassifier(number_of_hidden_neurons, 'relu', binarizer=CustomLabelBinirizer(), random_state=42),\n","             ]\n","\n","    ensemble = Ensemble(classifiers=models, program=genetic_programming(), apply_model_replacement=apply_model_replacement)\n","    return ensemble"],"metadata":{"id":"lsPgBdCHiwDE","executionInfo":{"status":"ok","timestamp":1695707841976,"user_tz":-180,"elapsed":2,"user":{"displayName":"Muawiya Al danaf","userId":"16999440410141197833"}}},"execution_count":9,"outputs":[]},{"cell_type":"code","source":["from sklearn.feature_selection import SelectFromModel\n","def random_forest_feature_selection(X, y):\n","    sel = SelectFromModel(RandomForestClassifier(n_estimators = 3))\n","    sel.fit(X, y)\n","    return sel.get_support()"],"metadata":{"id":"biu9pWsxhJc8","executionInfo":{"status":"ok","timestamp":1695707896666,"user_tz":-180,"elapsed":4,"user":{"displayName":"Muawiya Al danaf","userId":"16999440410141197833"}}},"execution_count":10,"outputs":[]},{"cell_type":"code","source":["def generate_new_samples(buffer, y_values, n=500, y_col='label'):\n","    if not y_col in buffer.columns.tolist():\n","      y_col = buffer.columns.tolist()[-1]\n","    if y_values.sum() == 0:\n","       return buffer[buffer[y_col] == 1].sample(n, random_state=41)[:, :-1].values, np.array([1] * n)\n","    else:\n","      return buffer[buffer[y_col] == 0].sample(n,random_state=41)[:, :-1].values, np.array([0] * n)"],"metadata":{"id":"pDtckNKAl28P"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def E2SC4ID(X,y,ensemble,drift_detection_obj):\n","  y_pred = ensemble.global_support_degree(X)\n","  if y is not None:\n","    drift = concept_drift_detection(drift_detection_obj, int(y!=y_pred))\n","    return drift\n","  return False"],"metadata":{"id":"8lBmBWACmPAb"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score, classification_report\n","def model_evaluation(X_train, X_test, y_train, y_test, selected_features, methode_name):\n","    print(25*\"-\",methode_name,25*\"-\")\n","    if not selected_features is None:\n","      subset_features = np.where(np.array(selected_features) == 1)[0]\n","      if subset_features.shape[0] == 0:return [0,0,0,0,0]\n","      print(sum(selected_features))\n","      print(subset_features)\n","      X_train, X_test = X_train[:,subset_features], X_test[:,subset_features]\n","    model = OSELMClassifier(X_train.shape[1]*3 // 2, 'relu', binarizer=CustomLabelBinirizer(), random_state=42)\n","    model.fit(X_train, y_train)\n","    y_pred = model.predict(X_test)\n","    f1 = f1_score(y_test, y_pred)\n","    recall = recall_score(y_test, y_pred)\n","    precision = precision_score(y_test, y_pred)\n","    accuracy = accuracy_score(y_test, y_pred)\n","    report = classification_report(y_test, y_pred)\n","    print(f1,recall,precision,accuracy)\n","    return f1,recall,precision,accuracy,y_pred"],"metadata":{"id":"1HQS2Wx4mu2d"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def main(f_name, generate_model, train_size=0.8,apply_model_replacement=False,transfer_learning=False,\n","         feature_selection=[], result_save_path=\"\",DFS_results_path='',ChunkNumber=0):\n","  datasets,results = {},{}\n","  d = prepare_data(f_name)\n","  d = d.sample(frac=1, random_state=42)\n","  buffer = d.sample(n=5000)\n","  d.reset_index(inplace=True)\n","  d.replace([np.inf], 0, inplace=True)\n","  datasets[f_name.split('/')[-1]] = d\n","  # drift_locations_in_all_dataset = {}\n","\n","  for key in tqdm(datasets.keys()):\n","      drift_detection_obj = ADWIN()\n","      ensemble = None\n","      result_save_path_data = os.path.join(result_save_path, key)\n","      drift_location = {}\n","      prediction_times = {}\n","      memory_reduction = {}\n","\n","      results[key] = {'model_result': []}\n","      data = datasets[key].values\n","      X, Y = data[:, 0:-1], data[:, -1].astype('int')\n","      if not os.path.exists(\"{}_evolving_matrix.pkl\".format(os.path.join(evolving_path, key))):\n","        a2 = np.random.randint(low=0, high=X.shape[1], size = X.shape[1] // 6).tolist()\n","        a3 = np.random.randint(low=0, high=X.shape[1], size = X.shape[1] // 5).tolist()\n","        a4 = np.random.randint(low=0, high=X.shape[1], size = X.shape[1] // 4).tolist()\n","        evolving_matrix = [a2, a3, a4]\n","        save_pickle(evolving_matrix, \"{}_evolving_matrix.pkl\".format(os.path.join(evolving_path, key)))\n","      else:\n","        evolving_matrix = load_pickle(\"{}_evolving_matrix.pkl\".format(os.path.join(evolving_path, key)))\n","      ensemble = generate_model(number_of_hidden_neurons=X.shape[1]*3 // 2, apply_model_replacement=apply_model_replacement)\n","      chunks_features = np.array_split(X, 10)\n","      chunks_labels = np.array_split(Y, 10)\n","      print(\"===================== dataset : {} ======================\".format(key))\n","      chunk_number = 1\n","      for CN,chunk_X, chunk_Y in tqdm(zip([*range(len(chunks_labels))],chunks_features, chunks_labels)):\n","          drift = False\n","          if chunk_number > 1:\n","            for i in tqdm(range(len(chunk_X))):\n","              if drift:\n","                drift_location[chunk_number] = 'drift'\n","                break\n","              x, y_true = chunk_X[i], chunk_Y[i]\n","              drift = E2SC4ID(x,y_true,ensemble=ensemble,drift_detection_obj=drift_detection_obj)\n","          try:\n","            chunk_X, chunk_Y = SMOTE(random_state=0).fit_resample(chunk_X, chunk_Y)\n","          except:\n","            if chunk_Y.sum() in [0, 1]:\n","              new_samples, new_labels = generate_new_samples(buffer, chunk_Y)\n","              chunk_X = np.concatenate((chunk_X, new_samples))\n","              chunk_Y = np.concatenate((chunk_Y, new_labels))\n","          gc.collect()\n","          unselected_feautres = None\n","          selected = None\n","          X_train, X_test, y_train, y_test = train_test_split(chunk_X, chunk_Y, random_state=42, train_size=train_size)\n","          if feature_selection[0] == \"feature_evolving\":\n","            unselected_feautres = feature_evolving(evolving_matrix=evolving_matrix)\n","            if feature_selection[1] == \"random_forest\":\n","              print(\"Evolving RandomForest\")\n","              selected = np.array(random_forest_feature_selection(X_train, y_train))\n","              selected1 = np.delete(selected, unselected_feautres)\n","              if sum(selected1)!=0:\n","                selected=selected1\n","                X_train = np.delete(X_train, unselected_feautres, 1)\n","                X_test = np.delete(X_test, unselected_feautres, 1)\n","              unselected_feautres = np.where(selected != 1)[0]\n","            elif feature_selection[1] == \"DFS_feature_selection\":\n","              print(\"Evolving DFS\")\n","              X_train = np.delete(X_train, unselected_feautres, 1)\n","              X_test = np.delete(X_test, unselected_feautres, 1)\n","              selected = load_best_mask_dfs(CN,DFS_results_path)\n","              selected = np.delete(selected, unselected_feautres)\n","              unselected_feautres = np.where(selected != 1)[0]\n","            else:\n","              print(\"Without Any FS\")\n","              X_train = np.delete(X_train, unselected_feautres, 1)\n","              X_test = np.delete(X_test, unselected_feautres, 1)\n","              selected = None\n","          else:\n","            if feature_selection[1] == \"random_forest\":\n","              print(\"RandomForest\")\n","              selected = random_forest_feature_selection(X_train, y_train)\n","              unselected_feautres = np.where(selected != 1)[0]\n","            elif feature_selection[1] == \"DFS_feature_selection\":\n","              print(\"DFS\")\n","              selected = load_best_mask_dfs(CN,DFS_results_path)\n","              unselected_feautres = np.where(selected != 1)[0]\n","            else:\n","              print(\"Without Any FS\")\n","              selected = None\n","              unselected_feautres = None\n","\n","          selected = [bool(bit) for bit in selected] if not selected is None else None\n","          if not os.path.exists(result_save_path_data):\n","            os.mkdir(result_save_path_data)\n","          if transfer_learning:\n","            if not selected is None:temp = np.squeeze(X_train[:, selected]) if len(list(X_train[:, selected].shape))>2 else X_train[:, selected]\n","            else:temp = X_train\n","\n","            ensemble,drift_detection_obj = E2SC4ID_STREAM(ensemble=ensemble, X=temp, y=y_train, unselected_features=None,drift_detection_obj=drift_detection_obj,\n","                                      chunk_number=chunk_number, result_save_path_data=result_save_path_data,drift=drift,transfer_learning=transfer_learning)\n","            if not selected is None:temp = np.squeeze(X_test[:, selected]) if len(list(X_test[:, selected].shape))>2 else X_test[:, selected]\n","            else:temp = X_test\n","            ensemble.evaluate(temp, y_test, chunk_number)\n","          else:\n","            init_ensemble=generate_model(number_of_hidden_neurons=X.shape[1]*3 // 2,apply_model_replacement=apply_model_replacement)\n","            if not ensemble is None:\n","              init_ensemble.set_scores(ensemble.get_scores())\n","            ensemble,drift_detection_obj = E2SC4ID_STREAM(ensemble=init_ensemble,X=X_train, y=y_train, unselected_features=unselected_feautres,drift_detection_obj=drift_detection_obj,\n","                                      chunk_number=chunk_number,result_save_path_data=result_save_path_data,drift=drift,transfer_learning=transfer_learning)\n","            ensemble.evaluate(X_test, y_test, chunk_number)\n","\n","\n","          if not selected is None:temp = np.squeeze(X_test[:, selected]) if len(list(X_test[:, selected].shape))>2 else X_test[:, selected]\n","          else:temp = X_test\n","          start_time = time()\n","          y_pre = ensemble.predict(temp)\n","          end_time = time()\n","          prediction_time = end_time - start_time\n","          prediction_times[chunk_number] = prediction_time\n","          memory_reduction[chunk_number] = temp.shape[1]\n","\n","          results[key][chunk_number] = {\"y_true\" : y_test, \"y_pred\": y_pre}\n","          results[key]['model_result'].append(ensemble.get_scores())\n","          if transfer_learning:\n","             ensemble.fit(temp, y_test, None)\n","          chunk_number += 1\n","          # drift_locations_in_all_dataset[key] = drift_location\n","\n","          save_pickle(drift_location, os.path.join(result_save_path_data, \"{}_drift_location.pkl\".format(key)))\n","          save_pickle(ensemble, os.path.join(result_save_path_data, \"{}_ensemble.pkl\".format(key)))\n","          save_pickle(results, os.path.join(result_save_path_data, \"{}_results.pkl\".format(key)))\n","          save_pickle(memory_reduction, os.path.join(result_save_path_data, \"{}_memory_reduction.pkl\".format(key)))\n","          save_pickle(prediction_times, os.path.join(result_save_path_data, \"{}_prediction_times.pkl\".format(key)))\n","          # save_pickle(drift_locations_in_all_dataset, os.path.join(result_save_path_data, \"{}_drift_locations_in_all_dataset.pkl\".format(key)))"],"metadata":{"id":"DSvzcmkCUcaU"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["data_name = ['kddcup99','ISCX2012','CSE-CIC2018','CICIDS2017','7recurrentDrift', 'blip', 'incrementalDrift','7gradualDrift', '7suddenDrift']\n","filenames = ['kddcup99_csv.csv','ISCX2012.csv','CSE-CIC2018.csv','CICIDS2017.csv','7recurrentDrift.csv', 'blip.csv', 'incrementalDrift.csv',\n","             '7gradualDrift.csv', '7suddenDrift.csv']\n","filenames = list(map(lambda x: os.path.join(data_path, x), filenames))\n","\n","for i,d_name in enumerate(data_name):\n","  datasets = {}\n","  drift_location = {}\n","  drift_detection_obj = DDM()\n","  d = prepare_data(filenames[i])\n","  d = d.sample(frac=1, random_state=42)\n","  buffer = d.sample(n=5000)\n","  d.reset_index(inplace=True)\n","  d.replace([np.inf], 0, inplace=True)\n","  datasets[filenames[i].split('/')[-1]] = d\n","  data = datasets[filenames[i].split('/')[-1]].values\n","  X, Y = data[:, 0:-1], data[:, -1].astype('int')\n","  ensemble = generate_oselm_models(number_of_hidden_neurons=X.shape[1]*3 // 2, apply_model_replacement=False)\n","  chunks_features = np.array_split(X, 10) #####################\n","  chunks_labels = np.array_split(Y, 10)   #####################\n","  print(30*\"*-\",d_name,30*\"*-\")\n","  DFS_results_path = os.path.join(feature_selection_results,d_name)\n","  Drift_Location_path = os.path.join(DriftLocation,d_name)\n","  os.makedirs(Drift_Location_path, exist_ok=True)\n","  for chunk_number,chunk_X, chunk_Y in tqdm(zip([*range(len(chunks_labels))],chunks_features, chunks_labels)):\n","    print(25*\"=\",chunk_number,25*\"=\")\n","    drift = False\n","    try:\n","      chunk_X, chunk_Y = SMOTE(random_state=0).fit_resample(chunk_X, chunk_Y) #######################\n","    except:\n","      if chunk_Y.sum() in [0, 1]:\n","        new_samples, new_labels = generate_new_samples(buffer, chunk_Y)\n","        chunk_X = np.concatenate((chunk_X, new_samples))\n","        chunk_Y = np.concatenate((chunk_Y, new_labels))\n","    gc.collect()\n","\n","    if chunk_number > 0:\n","      for i in tqdm(range(len(chunk_X))):\n","        if drift:\n","          drift_location[chunk_number] = 'drift'\n","          save_object(drift_location, \"drift_location\", Drift_Location_path)\n","          break\n","        x, y_true = chunk_X[i], chunk_Y[i]\n","        drift = E2SC4ID(x,y_true,ensemble=ensemble,drift_detection_obj=drift_detection_obj)\n","    else:\n","      pass\n","\n","    X_train, X_test, y_train, y_test = train_test_split(chunk_X, chunk_Y, random_state=42, train_size=0.80)\n","    model_evaluation(X_train, X_test, y_train, y_test, None, \"with_out_fs\")\n","\n","    softmax_mask = load_object(\"softmax_mask_\"+str(chunk_number),DFS_results_path)\n","    softmax_f1,_,_,_,_ = model_evaluation(X_train, X_test, y_train, y_test, softmax_mask,\"softmax\")\n","\n","    average_mask = load_object(\"average_mask_\"+str(chunk_number),DFS_results_path)\n","    average_f1,_,_,_,_ = model_evaluation(X_train, X_test, y_train, y_test, average_mask,\"average\")\n","\n","    single_agent_mask = load_object(\"single_agent_mask_\"+str(chunk_number),DFS_results_path)\n","    single_agent_f1,_,_,_,_ = model_evaluation(X_train, X_test, y_train, y_test, single_agent_mask,\"single_agent\")\n","\n","    random_forest_mask = load_object(\"random_forest_mask_\"+str(chunk_number),DFS_results_path)\n","    random_forest_f1,_,_,_,_ = model_evaluation(X_train, X_test, y_train, y_test, random_forest_mask,\"random_forest\")\n","\n","    voting_mask = load_object(\"voting_mask_\"+str(chunk_number),DFS_results_path)\n","    voting_f1,_,_,_,_ = model_evaluation(X_train, X_test, y_train, y_test, voting_mask,\"voting\")\n","\n","    # f1 = [softmax_f1,average_f1,single_agent_f1,random_forest_f1,voting_f1]\n","    # masks = [softmax_mask,average_mask,single_agent_mask,random_forest_mask,voting_mask]\n","    # max_f1 = max(f1)\n","    # best_mask = masks[f1.index(max_f1)]\n","\n","    # save_object(best_mask, \"best_mask_\"+str(chunk_number), DFS_results_path)\n","\n","    random_forest_ = np.array(random_forest_feature_selection(X_train, y_train))\n","    f1,_,_,_,_ = model_evaluation(X_train, X_test, y_train, y_test, random_forest_,\"random_forest_\")\n","    save_object(random_forest_, \"random_forest_base_\"+str(chunk_number), DFS_results_path)\n","    # best_f1,_,_,_,_ = model_evaluation(X_train, X_test, y_train, y_test, best_mask,\"best\")"],"metadata":{"id":"a3f_98leRkVH"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"ScrKgsKQRlHW"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def main(f_name, generate_model, train_size=0.8,apply_model_replacement=False,transfer_learning=False,\n","         feature_selection=[], result_save_path=\"\",DFS_results_path='',ChunkNumber=0):\n","          X_train, X_test, y_train, y_test = train_test_split(chunk_X, chunk_Y, random_state=42, train_size=train_size)\n","          if feature_selection[0] == \"feature_evolving\":\n","            unselected_feautres = feature_evolving(evolving_matrix=evolving_matrix)\n","            if feature_selection[1] == \"random_forest\":\n","              print(\"Evolving RandomForest\")\n","              selected = np.array(random_forest_feature_selection(X_train, y_train))\n","              selected1 = np.delete(selected, unselected_feautres)\n","              if sum(selected1)!=0:\n","                selected=selected1\n","                X_train = np.delete(X_train, unselected_feautres, 1)\n","                X_test = np.delete(X_test, unselected_feautres, 1)\n","              unselected_feautres = np.where(selected != 1)[0]\n","            elif feature_selection[1] == \"DFS_feature_selection\":\n","              print(\"Evolving DFS\")\n","              X_train = np.delete(X_train, unselected_feautres, 1)\n","              X_test = np.delete(X_test, unselected_feautres, 1)\n","              selected = load_best_mask_dfs(CN,DFS_results_path)\n","              selected = np.delete(selected, unselected_feautres)\n","              unselected_feautres = np.where(selected != 1)[0]\n","            else:\n","              print(\"Without Any FS\")\n","              X_train = np.delete(X_train, unselected_feautres, 1)\n","              X_test = np.delete(X_test, unselected_feautres, 1)\n","              selected = None\n","          else:\n","            if feature_selection[1] == \"random_forest\":\n","              print(\"RandomForest\")\n","              selected = random_forest_feature_selection(X_train, y_train)\n","              unselected_feautres = np.where(selected != 1)[0]\n","            elif feature_selection[1] == \"DFS_feature_selection\":\n","              print(\"DFS\")\n","              selected = load_best_mask_dfs(CN,DFS_results_path)\n","              unselected_feautres = np.where(selected != 1)[0]\n","            else:\n","              print(\"Without Any FS\")\n","              selected = None\n","              unselected_feautres = None\n","\n","          selected = [bool(bit) for bit in selected] if not selected is None else None\n","          if not os.path.exists(result_save_path_data):\n","            os.mkdir(result_save_path_data)\n","          if transfer_learning:\n","            if not selected is None:temp = np.squeeze(X_train[:, selected]) if len(list(X_train[:, selected].shape))>2 else X_train[:, selected]\n","            else:temp = X_train\n","\n","            ensemble,drift_detection_obj = E2SC4ID_STREAM(ensemble=ensemble, X=temp, y=y_train, unselected_features=None,drift_detection_obj=drift_detection_obj,\n","                                      chunk_number=chunk_number, result_save_path_data=result_save_path_data,drift=drift , transfer_learning=transfer_learning)\n","            if not selected is None:temp = np.squeeze(X_test[:, selected]) if len(list(X_test[:, selected].shape))>2 else X_test[:, selected]\n","            else:temp = X_test\n","            ensemble.evaluate(temp, y_test, chunk_number)\n","          else:\n","            init_ensemble=generate_model(number_of_hidden_neurons=X.shape[1]*3 // 2,apply_model_replacement=apply_model_replacement)\n","            if not ensemble is None:\n","              init_ensemble.set_scores(ensemble.get_scores())\n","            ensemble,drift_detection_obj = E2SC4ID_STREAM(ensemble=init_ensemble,X=X_train, y=y_train, unselected_features=unselected_feautres,drift_detection_obj=drift_detection_obj,\n","                                      chunk_number=chunk_number,result_save_path_data=result_save_path_data,transfer_learning=transfer_learning)\n","            ensemble.evaluate(X_test, y_test, chunk_number)\n","\n","\n","          if not selected is None:temp = np.squeeze(X_test[:, selected]) if len(list(X_test[:, selected].shape))>2 else X_test[:, selected]\n","          else:temp = X_test\n","          start_time = time()\n","          y_pre = ensemble.predict(temp)\n","          end_time = time()\n","          prediction_time = end_time - start_time\n","          prediction_times[chunk_number] = prediction_time\n","          memory_reduction[chunk_number] = temp.shape[1]\n","\n","          results[key][chunk_number] = {\"y_true\" : y_test, \"y_pred\": y_pre}\n","          results[key]['model_result'].append(ensemble.get_scores())\n","          if transfer_learning:\n","             ensemble.fit(temp, y_test, None)\n","          chunk_number += 1\n","          # drift_locations_in_all_dataset[key] = drift_location\n","\n","          save_pickle(drift_location, os.path.join(result_save_path_data, \"{}_drift_location.pkl\".format(key)))\n","          save_pickle(ensemble, os.path.join(result_save_path_data, \"{}_ensemble.pkl\".format(key)))\n","          save_pickle(results, os.path.join(result_save_path_data, \"{}_results.pkl\".format(key)))\n","          save_pickle(memory_reduction, os.path.join(result_save_path_data, \"{}_memory_reduction.pkl\".format(key)))\n","          save_pickle(prediction_times, os.path.join(result_save_path_data, \"{}_prediction_times.pkl\".format(key)))\n","          # save_pickle(drift_locations_in_all_dataset, os.path.join(result_save_path_data, \"{}_drift_locations_in_all_dataset.pkl\".format(key)))"],"metadata":{"id":"wmRogKBTRlJ_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"1bz2ghl_RlMm"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def plot_results(save_path,metric_name, methods_name, results, colors, step=1):\n","    plt.figure(figsize=(15, 5))\n","    plt.title(metric_name)\n","    for k, result in enumerate(results):\n","        x = [i for i, x in enumerate(results[k]) if i % step == 0]\n","        y = [x for i, x in enumerate(results[k]) if i % step == 0]\n","        plt.plot(x, y, color=colors[k], label=methods_name[k])\n","        plt.scatter(x, y, color=colors[k], s=20)\n","\n","    plt.legend(loc=\"best\")\n","    plt.xlabel('Chunk number')\n","    plt.ylabel('Results per Chunk')\n","\n","    plt.xticks()\n","    plt.gca().xaxis.set_major_locator(plt.MultipleLocator(step))\n","    plt.gca().xaxis.set_major_formatter(plt.ScalarFormatter(useOffset=False, useMathText=True))\n","\n","    plt.savefig(os.path.join(save_path, metric_name))\n","    plt.savefig(os.path.join(save_path, metric_name+'.svg'), format='svg')\n","    plt.show()"],"metadata":{"id":"OO5AB0Jm0rVp"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["data_name = ['kddcup99','ISCX2012','CSE-CIC2018','CICIDS2017','7recurrentDrift', 'blip', 'incrementalDrift','7gradualDrift', '7suddenDrift']\n","methods_name = ['Softmax <=> ALC','Average <=> AC','Single Agent <=> OA-OT','Random Forest <=> IM','Voting']\n","colors = ['r', 'g', 'b', 'm','y'] # , 'c'\n","metric_names = ['f1_score','recall_score','precision_score','accuracy_score']"],"metadata":{"id":"_-0qIg4m5prA"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["for d_name in data_name[:4]:\n","  load_path = os.path.join(feature_selection_results,d_name)\n","  save_path = os.path.join(os.path.join(feature_selection_results,'Images'),d_name)\n","  softmax_results = load_object(\"softmax_results\",load_path)\n","  average_results = load_object(\"average_results\",load_path)\n","  single_agent_results = load_object(\"single_agent_results\",load_path)\n","  random_forest_results = load_object(\"random_forest_results\",load_path)\n","  voting_results = load_object(\"voting_results\",load_path)\n","  os.makedirs(save_path, exist_ok=True)\n","  print(\"===================== dataset : {} ======================\".format(d_name))\n","  for i,metric_name in enumerate(list(softmax_results.keys())[:-1]):\n","    plot_results(save_path,metric_names[i]+\" with evolving\"+\" for \"+d_name, methods_name, [softmax_results[metric_name],average_results[metric_name],single_agent_results[metric_name],random_forest_results[metric_name],voting_results[metric_name]], colors, step=1)"],"metadata":{"id":"gVqBOsX375cb"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"CoCDKVNSvqwl"},"execution_count":null,"outputs":[]}]}