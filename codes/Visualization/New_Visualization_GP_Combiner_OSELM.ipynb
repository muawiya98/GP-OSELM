{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"5AYERK4_cyyj"},"outputs":[],"source":["from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report,confusion_matrix\n","from sklearn.model_selection import train_test_split\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.neighbors import KNeighborsClassifier\n","from warnings import simplefilter,filterwarnings\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.tree import DecisionTreeClassifier\n","from sklearn.preprocessing import OneHotEncoder\n","from matplotlib.colors import ListedColormap\n","from multiprocessing.pool import ThreadPool\n","from sklearn.naive_bayes import GaussianNB\n","from matplotlib.ticker import MaxNLocator\n","from sklearn.metrics import roc_auc_score\n","from imblearn.over_sampling import SMOTE\n","import matplotlib.ticker as mticker\n","import matplotlib.ticker as ticker\n","from sklearn.utils import shuffle\n","from contextlib import suppress\n","from collections import Counter\n","import matplotlib.pyplot as plt\n","from tqdm.notebook import tqdm\n","from random import shuffle\n","import seaborn as sns\n","from time import time\n","import pandas as pd\n","import numpy as np\n","import scipy.io\n","import pickle\n","import sys\n","import gc\n","import os\n","import re\n","filterwarnings('ignore')\n","filterwarnings(action='once')\n","os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n","simplefilter('ignore', FutureWarning)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"TBvNwKEy3OxE"},"outputs":[],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"U_6hgplnhcdh"},"outputs":[],"source":["root_path = '/content/drive/MyDrive/Colab_Notebooks/Muawiya/Genetic Programming Combiner with DFS'\n","code_path = os.path.join(root_path, 'Codes','Shared Codes')\n","data_path =  os.path.join(root_path, 'data')\n","results_path = os.path.join(root_path, 'Results')\n","image_path = os.path.join(root_path, 'Images')\n","csv_path = os.path.join(root_path, 'CSV')\n","\n","folders_evolving = [\"kpfaoselm_gp_combiner_with_model_replacement_evolving_random_forest\",\n","                    \"kpfaoselm_gp_combiner_with_model_replacement_evolving_DFS\",\n","                    \"kpfaoselm_gp_combiner_with_model_replacement_evolving\",\n","                    \"kpfaoselm_gp_combiner_with_model_replacement_evolving_IssamDFS\",\n","                    ]\n","\n","folders_without_evolving = [\"kpfaoselm_gp_combiner_with_model_replacement_random_forest\",\n","                            \"kpfaoselm_gp_combiner_with_model_replacement_DFS\",\n","                            \"kpfaoselm_gp_combiner_with_model_replacement\",\n","                            \"kpfaoselm_gp_combiner_with_model_replacement_IssamDFS\",\n","                            ]\n","algo_name = 'kpfaoselm_gp'\n","\n","\n","# folders_evolving = [\"faoselm_gp_combiner_with_model_replacement_evolving_random_forest\",\n","#                     \"faoselm_gp_combiner_with_model_replacement_evolving_DFS\",\n","#                     \"faoselm_gp_combiner_with_model_replacement_evolving\",\n","#                     \"faoselm_gp_combiner_with_model_replacement_evolving_IssamDFS\",\n","#                     ]\n","# folders_without_evolving = [\"faoselm_gp_combiner_with_model_replacement_random_forest\",\n","#                             \"faoselm_gp_combiner_with_model_replacement_DFS\",\n","#                             \"faoselm_gp_combiner_with_model_replacement\",\n","#                             \"faoselm_gp_combiner_with_model_replacement_IssamDFS\",\n","#                             ]\n","# algo_name = 'faoselm_gp'\n","\n","\n","# folders_evolving = [\"gp_combiner_with_model_replacement_evolving_random_forest\",\n","#                     \"gp_combiner_with_model_replacement_evolving_DFS\",\n","#                     \"gp_combiner_with_model_replacement_evolving\",\n","#                     \"gp_combiner_with_model_replacement_evolving_IssamDFS\",\n","#                     ]\n","# folders_without_evolving = [\"gp_combiner_with_model_replacement_random_forest\",\n","#                             \"gp_combiner_with_model_replacement_DFS\",\n","#                             \"gp_combiner_with_model_replacement\",\n","#                             \"gp_combiner_with_model_replacement_IssamDFS\",\n","#                             ]\n","# algo_name = 'gp'\n","\n","\n","sys.path.insert(0,code_path)\n","from ensemble import Ensemble, Classifier"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qdn3Zzj9eS3m"},"outputs":[],"source":["filenames = ['ISCX2012.csv', 'CSE-CIC2018.csv', 'CICIDS2017.csv', 'kddcup99_csv.csv', 'Blip_Drift.csv',\n","             'Gradual_Drift.csv', 'Incremental_Drift.csv', 'Recurrent_Drift.csv', 'Sudden_Drift.csv']\n","files = list(map(lambda x: os.path.join(data_path, x), filenames))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0RwOkmaf4blN"},"outputs":[],"source":["def save_object(obj, filename,path):\n","    filename = os.path.join(path,filename)\n","    with open(filename+\".pkl\", 'wb') as outp:\n","        pickle.dump(obj, outp, pickle.HIGHEST_PROTOCOL)\n","    outp.close()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"vIPSb64A4dZ9"},"outputs":[],"source":["def load_object(filename,path):\n","    filename = os.path.join(path,filename)\n","    with open(filename+\".pkl\", 'rb') as outp:\n","        loaded_object = pickle.load(outp)\n","    outp.close()\n","    return loaded_object"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Kcy_-pAvPjWY"},"outputs":[],"source":["def save_pickle(obj, file_name):\n","  with open(file_name, 'wb') as f:\n","    pickle.dump(obj, f)\n","def load_pickle(file_name):\n","  with open(file_name, 'rb') as f:\n","    d = pickle.load(f)\n","  return d"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"UeXcoxxGZe2h"},"outputs":[],"source":["def plot_results(metric_name, methods_name, results, colors, data_name, algo_name, drift_location=None, Name=\"\", step=1):\n","    plt.figure(figsize=(25, 8))\n","    plt.title(data_name+\" \"+Name)\n","    numerecal_results = pd.DataFrame()\n","    # for k, result in enumerate(results):\n","    #     print(k, methods_name[k], data_name, len(result))\n","    #     if not drift_location is None:\n","    #       print(drift_location[k])\n","    for k, result in enumerate(results):\n","        # x = np.arange(step, len(result) + step, step)\n","        # y = result[::step]\n","\n","        x = [i for i, x in enumerate(results[k]) if i % step == 0]\n","        y = [x for i, x in enumerate(results[k]) if i % step == 0]\n","\n","        numerecal_results[methods_name[k]] = y\n","        plt.plot(x, y, color=colors[k], label=methods_name[k])\n","        plt.scatter(x, y, color=colors[k], s=20)  # Add dots to the plot\n","        if not drift_location is None:\n","          for loc in drift_location[k]:\n","            if type(loc) is str : continue\n","            loc = loc-1\n","            y_value = y[loc]\n","            plt.plot(loc, y_value, marker=\"o\", markersize=9, markerfacecolor=colors[k])\n","    plt.legend(loc=\"best\")\n","    plt.xlabel('Chunk number')\n","    plt.ylabel(metric_name)\n","\n","    ax = plt.gca()\n","    ax.locator_params(axis='y', nbins=15)\n","    ax.yaxis.set_major_locator(MaxNLocator(nbins=15))\n","\n","    num_ticks = 50  # Change this value to adjust the number of ticks\n","    ax.xaxis.set_major_locator(plt.MaxNLocator(num_ticks))\n","\n","    ax.xaxis.set_major_formatter(plt.ScalarFormatter(useOffset=False, useMathText=True))\n","    ax.xaxis.set_minor_locator(ticker.AutoMinorLocator())\n","    plt.xticks(rotation=45, fontsize='xx-small')\n","    plt.grid()\n","\n","    # Format x-axis ticks as integers\n","    plt.gca().xaxis.set_major_locator(plt.MultipleLocator(step))\n","    plt.gca().xaxis.set_major_formatter(plt.ScalarFormatter(useOffset=False, useMathText=True))\n","    my_path = os.path.join(image_path,\"{}\".format(data_name))\n","    os.makedirs(my_path, exist_ok=True)\n","    numerecal_results.to_csv(os.path.join(my_path,\"{}.csv\".format(algo_name+\"_\"+metric_name+\"_\"+Name)), index=False)\n","    plt.savefig(os.path.join(my_path, algo_name+\"_\"+metric_name+\"_\"+Name))\n","    plt.savefig(os.path.join(my_path, algo_name+\"_\"+metric_name+\"_\"+Name+'.svg'), format='svg')\n","    plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"UXZgYYOk4Tz0"},"outputs":[],"source":["def plot_dimensional_reduction(metric_name, methods_name, results, colors, data_name,drift_location=None, Name=\"\", step=1):\n","  barWidth = 0.25\n","  fig = plt.subplots(figsize=(15, 5))\n","  numerecal_results = pd.DataFrame()\n","  plt.title(data_name+\" \"+Name)\n","  br1 = np.arange(len(results[0]))\n","  br = [br1]\n","  for i in results[:-1]:\n","    br1 = [x + barWidth for x in br1]\n","    br.append(br1)\n","\n","  for i, res in enumerate(results):\n","    numerecal_results[methods_name[i]] = res\n","    plt.bar(br[i], res, color=colors[i], width=barWidth, edgecolor=colors[i], label=methods_name[i])\n","\n","  plt.legend(loc=\"best\")\n","  plt.xlabel('Chunk number')\n","  plt.ylabel(metric_name)\n","\n","  plt.xticks(rotation=45, fontsize='xx-small')\n","  plt.gca().xaxis.set_major_locator(plt.MultipleLocator(step))\n","  plt.gca().xaxis.set_major_formatter(plt.ScalarFormatter(useOffset=False, useMathText=True))\n","  my_path = os.path.join(image_path,\"{}\".format(data_name))\n","  os.makedirs(my_path, exist_ok=True)\n","  numerecal_results.to_csv(os.path.join(my_path,\"{}.csv\".format(metric_name+\"_\"+Name)), index=False)\n","  plt.savefig(os.path.join(my_path, metric_name+\"_\"+Name))\n","  plt.savefig(os.path.join(my_path, metric_name+\"_\"+Name+'.svg'), format='svg')\n","  plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"cgRE8W2Uukgn"},"outputs":[],"source":["def Finall_Results(folders,Name=\"\"):\n","  df_accuracy, df_precision , df_recall , df_f1_score, df_auc, df_drift_location = pd.DataFrame(), pd.DataFrame(), pd.DataFrame(), pd.DataFrame(), pd.DataFrame(), pd.DataFrame()\n","  method_names = [\"GPC-KOS-RF\",\"GPC-KOS-DFS\", \"GPC-OS\",\"GPC-KOS-DQN-MAFS\"]\n","  # method_names = [\"GPC-FOS-RF\",\"GPC-FOS-DFS\", \"GPC-OS\",\"GPC-FOS-DQN-MAFS\"]\n","  # method_names = [\"GPC-OS-RF\",\"GPC-OS-DFS\", \"GPC-OS\",\"GPC-OS-DQN-MAFS\"]\n","\n","\n","  synthetic_data = ['Blip', 'GradualDrift', 'Incremental', 'Recurrent', 'SuddenDrift']\n","\n","  data_names = ['ISCX2012', 'CSE-CIC2018', 'CICIDS2017', 'KddCup99', 'Blip',\n","                'GradualDrift', 'Incremental', 'Recurrent', 'SuddenDrift']\n","\n","\n","  df_accuracy['data_names'],df_precision['data_names'] =  data_names, data_names\n","  df_f1_score['data_names'],df_recall['data_names'] = data_names, data_names\n","  df_auc['data_names'], df_drift_location['data_names'] = data_names, data_names\n","\n","\n","  metrices = [\"accuracy\", \"precision\", \"recall\", \"f1-score\", \"auc\"]\n","  # colors = ['g', 'r', 'cyan', 'gray', 'y','blue','black','orange','magenta']\n","  colors = ['g', 'r', 'b','orange']\n","\n","  for i, data in enumerate(filenames):\n","    accuracys, precisions, recalls, f1_scores, aucs, drift_location, memory_reduction, prediction_times = [], [], [], [], [], [], [], []\n","    for j,folder in enumerate(folders):\n","      results = load_object(data+\"_ensemble\",os.path.join(os.path.join(results_path,folder),data)).scores\n","      accuracy, precision , recall , f1_score, auc = [], [], [], [], []\n","      for key in results.keys():\n","        result = results[key]\n","        accuracy.append(result[metrices[0]])\n","        precision.append(result[metrices[1]])\n","        recall.append(result[metrices[2]])\n","        f1_score.append(result[metrices[3]])\n","        auc.append(result[metrices[4]])\n","\n","      accuracys.append(accuracy)\n","      precisions.append(precision)\n","      recalls.append(recall)\n","      f1_scores.append(f1_score)\n","      aucs.append(auc)\n","      if data_names[i] in synthetic_data: drift_location.append([25,50,75])\n","      else:\n","        drift_location.append(list(load_object(data+\"_drift_location\",os.path.join(os.path.join(results_path,folder),data)).keys()))\n","\n","      memory_reduction.append(list(load_object(data+\"_memory_reduction\",os.path.join(os.path.join(results_path,folder),data)).values()))\n","      prediction_times.append(list(load_object(data+\"_prediction_times\",os.path.join(os.path.join(results_path,folder),data)).values()))\n","\n","\n","    # plot_dimensional_reduction(metrices[0], method_names, accuracys, colors, data_names[i], drift_location, Name, step=1)\n","    # plot_dimensional_reduction(metrices[3], method_names, f1_scores, colors, data_names[i], drift_location, Name, step=1)\n","    # plot_dimensional_reduction(metrices[1], method_names, precisions, colors, data_names[i], drift_location, Name, step=1)\n","    # plot_dimensional_reduction(metrices[2], method_names, recalls, colors, data_names[i], drift_location, Name, step=1)\n","    # plot_dimensional_reduction(metrices[4], method_names, aucs, colors, data_names[i], drift_location, Name, step=1)\n","    # plot_dimensional_reduction(\"Memory Reduction\", method_names, memory_reduction, colors, data_names[i], Name=Name, step=1)\n","    # plot_dimensional_reduction(\"Prediction Times\", method_names, prediction_times, colors, data_names[i], Name=Name, step=1)\n","\n","\n","    for accuracy, precision , recall , f1_score, auc ,method_name in  zip(accuracys, precisions, recalls, f1_scores, aucs, method_names):\n","      df_accuracy.at[i,method_name] =  np.average(accuracy)\n","      df_precision.at[i,method_name] =  np.average(precision)\n","      df_recall.at[i,method_name] = np.average(recall)\n","      df_f1_score.at[i,method_name] =  np.average(f1_score)\n","      df_auc.at[i,method_name] = np.average(auc)\n","    plot_results(metrices[0], method_names, accuracys, colors, data_names[i], algo_name, drift_location, Name, step=1)\n","    plot_results(metrices[3], method_names, f1_scores, colors, data_names[i], algo_name, drift_location, Name, step=1)\n","    plot_results(metrices[1], method_names, precisions, colors, data_names[i], algo_name, drift_location, Name, step=1)\n","    plot_results(metrices[2], method_names, recalls, colors, data_names[i], algo_name, drift_location, Name, step=1)\n","    plot_results(metrices[4], method_names, aucs, colors, data_names[i], algo_name, drift_location, Name, step=1)\n","    plot_results(\"Memory Usage\", method_names, memory_reduction, colors, data_names[i], algo_name, Name=Name, step=1)\n","    plot_results(\"Prediction Times\", method_names, prediction_times, colors, data_names[i], algo_name, Name=Name, step=1)\n","\n","  df_auc.to_csv(os.path.join(csv_path,algo_name+\"_auc_\"+Name.lower()+\".csv\"), index=False)\n","  df_f1_score.to_csv(os.path.join(csv_path,algo_name+\"_f1_score_\"+Name.lower()+\".csv\"), index=False)\n","  df_recall.to_csv(os.path.join(csv_path,algo_name+\"_recall_\"+Name.lower()+\".csv\"), index=False)\n","  df_precision.to_csv(os.path.join(csv_path,algo_name+\"_precision_\"+Name.lower()+\".csv\"), index=False)\n","  df_accuracy.to_csv(os.path.join(csv_path,algo_name+\"_accuracy_\"+Name.lower()+\".csv\"), index=False)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"lWt_pkJQ2M7j"},"outputs":[],"source":["Finall_Results(folders=folders_evolving,Name=\"With Evolving\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"w0waWXjp2N3Z"},"outputs":[],"source":["Finall_Results(folders=folders_without_evolving,Name=\"Without Evolving\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"v-61HOSHfClu"},"outputs":[],"source":[]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}