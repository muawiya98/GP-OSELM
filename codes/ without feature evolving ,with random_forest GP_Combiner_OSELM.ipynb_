{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":19,"status":"ok","timestamp":1689155377264,"user":{"displayName":"yazan rac","userId":"13751022945634073261"},"user_tz":-180},"id":"XJ6GVAlZMq75","outputId":"0ad4d0f1-cff3-4935-99a6-2df72cfd96d8"},"outputs":[{"output_type":"stream","name":"stdout","text":["Print without warning\n"]}],"source":["import warnings\n","import os\n","\n","warnings.filterwarnings(\"ignore\")\n","warnings.filterwarnings(\"ignore\", category=UserWarning, module=\"tensorflow\")\n","\n","# Redirect warnings to null device\n","with open(os.devnull, \"w\") as devnull:\n","    with warnings.catch_warnings():\n","        warnings.simplefilter(\"ignore\")\n","        warnings.warn(\"This is a sample warning.\")  # Example warning that will be suppressed\n","\n","        # Rest of your code\n","\n","print(\"Print without warning\")"]},{"cell_type":"markdown","metadata":{"id":"ENba-xf5PBPw"},"source":["# Import required Modules\n","* install scikit-multiflow to import drift detection algorithm\n","* Mount on google drive to load datasets."]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":22605,"status":"ok","timestamp":1689155399856,"user":{"displayName":"yazan rac","userId":"13751022945634073261"},"user_tz":-180},"id":"hrQXfAEAWiXu","outputId":"40728b83-0dc6-4041-b32b-09b61dfa50e5"},"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/450.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m450.6/450.6 kB\u001b[0m \u001b[31m32.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Building wheel for scikit-multiflow (setup.py) ... \u001b[?25l\u001b[?25hdone\n"]}],"source":["!pip install -q scikit-multiflow"]},{"cell_type":"code","execution_count":3,"metadata":{"id":"5AYERK4_cyyj","executionInfo":{"status":"ok","timestamp":1689155401282,"user_tz":-180,"elapsed":1436,"user":{"displayName":"yazan rac","userId":"13751022945634073261"}}},"outputs":[],"source":["from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report\n","from sklearn.model_selection import train_test_split\n","from sklearn.linear_model import LogisticRegression\n","from skmultiflow.drift_detection import ADWIN, DDM\n","from sklearn.neighbors import KNeighborsClassifier\n","# from warnings import simplefilter,filterwarnings\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.tree import DecisionTreeClassifier\n","from sklearn.preprocessing import OneHotEncoder\n","from matplotlib.colors import ListedColormap\n","from multiprocessing.pool import ThreadPool\n","from sklearn.naive_bayes import GaussianNB\n","from sklearn.metrics import roc_auc_score\n","from imblearn.over_sampling import SMOTE\n","from sklearn.utils import shuffle\n","from contextlib import suppress\n","from collections import Counter\n","import matplotlib.pyplot as plt\n","from tqdm.notebook import tqdm\n","from random import shuffle\n","import seaborn as sns\n","from time import time\n","import pandas as pd\n","import numpy as np\n","import warnings\n","import scipy.io\n","import pickle\n","import sys\n","import gc\n","import os\n","import re\n","# filterwarnings('ignore')\n","# filterwarnings(action='once')\n","# warnings.filterwarnings(\"ignore\", message=\"Skipping variable loading for optimizer 'Adam', because it has 13 variables whereas the saved optimizer has 1 variables.\")\n","# warnings.filterwarnings(\"ignore\", category=UserWarning, module=\"tensorflow\")\n","# os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n","# # simplefilter('ignore', FutureWarning)\n","# with suppress(WARNING):"]},{"cell_type":"code","execution_count":4,"metadata":{"id":"8olPvcq9eH2q","executionInfo":{"status":"ok","timestamp":1689155401284,"user_tz":-180,"elapsed":14,"user":{"displayName":"yazan rac","userId":"13751022945634073261"}}},"outputs":[],"source":["# from IPython.display import HTML\n","\n","# HTML('''<script>\n","# var code_show_err = false;\n","# var code_toggle_err = function() {\n","#     var stderrNodes = document.querySelectorAll('[data-mime-type=\"application/vnd.jupyter.stderr\"]')\n","#     var stderr = Array.from(stderrNodes)\n","#     if (code_show_err){\n","#         stderr.forEach(ele => ele.style.display = 'block');\n","#     } else {\n","#         stderr.forEach(ele => ele.style.display = 'none');\n","#     }\n","#     code_show_err = !code_show_err\n","# }\n","# document.addEventListener('DOMContentLoaded', code_toggle_err);\n","# </script>\n","# To toggle on/off output_stderr, click <a onclick=\"javascript:code_toggle_err()\">here</a>.''')"]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3006147,"status":"ok","timestamp":1689158407420,"user":{"displayName":"yazan rac","userId":"13751022945634073261"},"user_tz":-180},"id":"TBvNwKEy3OxE","outputId":"ab4f7ad9-24a3-464a-80b5-661cf587d3aa"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":6,"metadata":{"id":"6cX3kM3dKNyC","executionInfo":{"status":"ok","timestamp":1689158407447,"user_tz":-180,"elapsed":95,"user":{"displayName":"yazan rac","userId":"13751022945634073261"}}},"outputs":[],"source":["data_path = '/content/drive/My Drive/Colab Notebooks/Muawiya/Genetic Programming Combiner with DFS/data'\n","code_path = '/content/drive/My Drive/Colab Notebooks/Muawiya/Genetic Programming Combiner with DFS/codes'\n","results_path = '/content/drive/My Drive/Colab Notebooks/Muawiya/Genetic Programming Combiner with DFS/results'"]},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":11483,"status":"ok","timestamp":1689158418844,"user":{"displayName":"yazan rac","userId":"13751022945634073261"},"user_tz":-180},"id":"haULZUPaXxm_","outputId":"b73a8b5b-af74-44ec-a3a4-d37d3450bc1d"},"outputs":[{"output_type":"stream","name":"stdout","text":["Print without warning\n","Print without warning\n","Print without warning\n","Print without warning\n"]}],"source":["sys.path.insert(0,code_path)\n","from genetic_programming import SymbolicRegressor\n","from binirizer import CustomLabelBinirizer\n","from ensemble import Ensemble, Classifier\n","from oselm import OSELMClassifier,set_use_know\n","from DynamicFeatureSelection import dynamic_feature_selection"]},{"cell_type":"code","execution_count":8,"metadata":{"id":"f-8t5nsOF7ru","executionInfo":{"status":"ok","timestamp":1689158418856,"user_tz":-180,"elapsed":225,"user":{"displayName":"yazan rac","userId":"13751022945634073261"}}},"outputs":[],"source":["# ldseg=np.array(os.listdir(data_path))\n","# for filename in ldseg:\n","#   dst = re.sub('نسخة من ', '', filename)\n","#   src = os.path.join(data_path,filename)\n","#   dst = ospath.join(d, dst)\n","#   os.rename(src, dst)"]},{"cell_type":"code","execution_count":9,"metadata":{"id":"bz3rqClBP1Cb","executionInfo":{"status":"ok","timestamp":1689158418858,"user_tz":-180,"elapsed":224,"user":{"displayName":"yazan rac","userId":"13751022945634073261"}}},"outputs":[],"source":["# this files (genetic_programming, label_binirizer, pyoselm) must be uploaded to the google colab to be imported correctly.\n","# try:\n","#     del sys.modules['binirizer']\n","#     del sys.modules['genetic_programming']\n","#     del sys.modules['oselm']\n","# except:\n","#     pass"]},{"cell_type":"code","execution_count":10,"metadata":{"id":"ws992JHCwMnB","executionInfo":{"status":"ok","timestamp":1689158418859,"user_tz":-180,"elapsed":222,"user":{"displayName":"yazan rac","userId":"13751022945634073261"}}},"outputs":[],"source":["# from utils import load_pickle, save_pickle"]},{"cell_type":"markdown","metadata":{"id":"h6l8bXW7PTDf"},"source":["# 1. Dataset Preprocessing :\n","* read the dataset using pnadas read_csv function.\n","* change the column names to numerical values\n","* apply label encoding on the vlaues of target variables (map each string value to numeric vlaue)"]},{"cell_type":"code","execution_count":11,"metadata":{"id":"LUR4beVl1Vw_","executionInfo":{"status":"ok","timestamp":1689158418860,"user_tz":-180,"elapsed":215,"user":{"displayName":"yazan rac","userId":"13751022945634073261"}}},"outputs":[],"source":["class Classifier:\n","    def __init__(self, clf, max_number_of_classes:int=2):\n","        \"\"\"\n","        Wrapping sklearn classifiers\n","        clf: sklearn classifiers like (KNN, LogRegression, DecisionTree, etc...)\n","        max_number_of_classes: integer, number of unique values in the predicted variable.\n","        \"\"\"\n","        self.clf = clf\n","        # decision profile contains the prediction probability values.\n","        self.decision_profile = None\n","        self.max_number_of_classes = max_number_of_classes\n","\n","\n","    # fit the classifier\n","    def fit(self, X_train, y_train, unselected_features=None):\n","        \"\"\"\n","        Call the training function\n","        X_train: 2d array with shape num_of_samples x num_of_feautres.\n","        y_train: 1d array with shape (num_of_samples, ) contains the ground truth values.\n","        \"\"\"\n","        # X_train = np.array(X_train) if not type(X_train).__module__ == np.__name__ else X_train\n","        # y_train = np.array(y_train) if not type(y_train).__module__ == np.__name__ else y_train\n","        # print(\"X_train : \",X_train.shape)\n","        # print(\"y_train : \",y_train.shape)\n","        if type(self.clf) == OSELMClassifier:\n","            self.clf.fit(X_train, y_train, unselected_features)\n","        else:\n","            # print(\"1234\")\n","            self.clf.fit(X_train, y_train)\n","            # print(type(self.clf))\n","\n","    def predict_proba(self, X):\n","        \"\"\"\n","        predict the probability of belonging this `sample` to each class\n","        \"\"\"\n","        # sometimes number of unique values in the predicted variable differ from one chunk to another,\n","        # so that we need to pad the results of probablity prediction to new size equal to `max_number_of_classes`\n","\n","        pred = self.clf.predict_proba(X)\n","        return pred\n","\n","    def build_decision_profile(self, sample):\n","        \"\"\"\n","        add the predict_probability result to the `decision_profile` list\n","        sample: one example form the dataset\n","        \"\"\"\n","        self.decision_profile = self.predict_proba(sample.reshape((1, -1)))[0].tolist()\n","\n","\n","class Ensemble:\n","    def __init__(self, classifiers, program, apply_model_replacement):\n","\n","        \"\"\"\n","        classfiers : list of Classifier objects\n","        program: result of genetic programming (SymbolicRegressor)\n","        \"\"\"\n","        self.classifiers = classifiers\n","        self.program = program\n","        self.program_history = []\n","        self.fitted = False\n","        self.scores = {}\n","        self.apply_model_replacement = apply_model_replacement\n","\n","    def fit(self, X_train, y_train, unselected_features=None):\n","        self.classifier_induction(self.classifiers, X_train, y_train, unselected_features=unselected_features)\n","        self.update_program(X_train, y_train)\n","\n","\n","    def classifier_induction(self, new_classifiers, X_train:np.array, y_train:np.array, unselected_features:list=None)->list:\n","        \"\"\"\n","        new_classifiers: list of new classifiers to insert them into ensemble classifiers.\n","        X_train: training dataset .\n","        y_train: ground truth values.\n","        unselected_features: indices of unselected features at each chunk\n","        ----------------------------------------------------------------\n","        return new_classifiers after training.\n","        \"\"\"\n","        # use classifier_induction_util for multiprocessing\n","        def classifier_induction_util(classifier):\n","            clf = Classifier(classifier, 2)\n","            clf.fit(X_train.copy(), y_train.copy(), unselected_features)\n","            return clf\n","        # train each new classifier in parallel\n","        trained_classifiers = ThreadPool(len(new_classifiers)).map(classifier_induction_util, new_classifiers)\n","        # add the trained classifiers to the ensemble classifiers.\n","        if self.apply_model_replacement:\n","          self.classifiers += trained_classifiers\n","        else:\n","          self.classifiers = trained_classifiers\n","        # return the trained classifiers (new classifiers after training)\n","        return trained_classifiers\n","\n","    def model_replacement(self, criteria='best'):\n","        if criteria == 'best':\n","          pass\n","        elif criteria == 'time':\n","          self.classifiers = self.classifiers[3:]\n","\n","\n","    def global_support_degree(self, sample):\n","        for i,clf in enumerate(self.classifiers):\n","            if not isinstance(clf,Classifier):\n","              clf = Classifier(clf,2)\n","              self.classifiers[i] = clf\n","            clf.build_decision_profile(sample)\n","        profile = np.array([self.classifiers[i].decision_profile for i in range(len(self.classifiers))])\n","        return np.argmax(profile.sum(axis=0))\n","\n","    def update_program(self, X, y):\n","        # change the fit flag to True.\n","        self.fitted = True\n","        profiles = np.array([self.classifiers[i].predict_proba(X) for i in range(len(self.classifiers))])\n","        self.program.fit(profiles, y)\n","        self.program_history.append(self.program)\n","\n","\n","    def predict(self, X_test):\n","        X_test = np.squeeze(X_test) if len(list(X_test.shape))>2 else X_test\n","        profiles = np.array([self.classifiers[i].predict_proba(X_test) for i in range(len(self.classifiers))])\n","        return self.program.predict(profiles)\n","\n","    def evaluate(self, X_test, y_test, chunk_id=1):\n","        y_pred = self.predict(X_test)\n","        # accuracy_score, precision_score, recall_score, f1_score\n","        try:\n","          auc = roc_auc_score(y_test, y_pred)\n","        except:\n","          auc = 0.5\n","        self.scores[chunk_id] = {\"accuracy\": accuracy_score(y_test, y_pred),\n","                                 \"precision\": precision_score(y_test, y_pred),\n","                                 \"recall\": recall_score(y_test, y_pred),\n","                                 \"f1-score\": f1_score(y_test, y_pred),\n","                                 \"auc\": auc}\n","        print(self.scores)\n"]},{"cell_type":"markdown","metadata":{"id":"XJT1aSKY7IMP"},"source":["# Componentes"]},{"cell_type":"code","execution_count":12,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":212,"status":"ok","timestamp":1689158418862,"user":{"displayName":"yazan rac","userId":"13751022945634073261"},"user_tz":-180},"id":"qdn3Zzj9eS3m","outputId":"b9abe48d-606c-4674-cb46-ef052fd1154c"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["['/content/drive/My Drive/Colab Notebooks/Muawiya/Genetic Programming Combiner with DFS/data/kddcup99_csv.csv',\n"," '/content/drive/My Drive/Colab Notebooks/Muawiya/Genetic Programming Combiner with DFS/data/ISCX2012.csv',\n"," '/content/drive/My Drive/Colab Notebooks/Muawiya/Genetic Programming Combiner with DFS/data/CSE-CIC2018.csv',\n"," '/content/drive/My Drive/Colab Notebooks/Muawiya/Genetic Programming Combiner with DFS/data/CICIDS2017.csv',\n"," '/content/drive/My Drive/Colab Notebooks/Muawiya/Genetic Programming Combiner with DFS/data/7recurrentDrift.csv',\n"," '/content/drive/My Drive/Colab Notebooks/Muawiya/Genetic Programming Combiner with DFS/data/blip.csv',\n"," '/content/drive/My Drive/Colab Notebooks/Muawiya/Genetic Programming Combiner with DFS/data/incrementalDrift.csv',\n"," '/content/drive/My Drive/Colab Notebooks/Muawiya/Genetic Programming Combiner with DFS/data/7gradualDrift.csv',\n"," '/content/drive/My Drive/Colab Notebooks/Muawiya/Genetic Programming Combiner with DFS/data/7suddenDrift.csv']"]},"metadata":{},"execution_count":12}],"source":["filenames = ['kddcup99_csv.csv','ISCX2012.csv','CSE-CIC2018.csv','CICIDS2017.csv','7recurrentDrift.csv', 'blip.csv', 'incrementalDrift.csv',\n","             '7gradualDrift.csv', '7suddenDrift.csv']\n","filenames = list(map(lambda x: os.path.join(data_path, x), filenames))\n","filenames"]},{"cell_type":"code","execution_count":13,"metadata":{"id":"C0x2_IFYdQ_J","executionInfo":{"status":"ok","timestamp":1689158418863,"user_tz":-180,"elapsed":165,"user":{"displayName":"yazan rac","userId":"13751022945634073261"}}},"outputs":[],"source":["def prepare_data(csv_filename, target_column_name='class'):\n","    # read csv file\n","    df = pd.read_csv(csv_filename)\n","    df = df.iloc[:80000, :]\n","    column_names = df.columns.tolist()\n","    if target_column_name not in column_names:\n","        target_column_name = column_names[-1]\n","    # get unique value in target column\n","    unique_vlaues = sorted(df[target_column_name].unique().tolist())\n","    df[target_column_name] = df[target_column_name].apply(lambda x: 0 if x == unique_vlaues[0] else 1)\n","    df[target_column_name] = df[target_column_name].astype('int')\n","    # rename the column of the dataframe\n","    num_of_columns = len(column_names)\n","    df.columns = list(range(num_of_columns))\n","    return df"]},{"cell_type":"code","execution_count":14,"metadata":{"id":"SnvpWgAOea6P","executionInfo":{"status":"ok","timestamp":1689158418864,"user_tz":-180,"elapsed":163,"user":{"displayName":"yazan rac","userId":"13751022945634073261"}}},"outputs":[],"source":["def train_and_test(model, X_train, y_train, X_test, y_test, unselected_features=None):\n","    model.fit(X_train, y_train, unselected_features)\n","    y_pred = model.predict(X_test)\n","    model.fit(X_test, y_test, unselected_features)\n","    return model, y_pred"]},{"cell_type":"code","execution_count":15,"metadata":{"id":"voLanNr9zsZE","executionInfo":{"status":"ok","timestamp":1689158418866,"user_tz":-180,"elapsed":161,"user":{"displayName":"yazan rac","userId":"13751022945634073261"}}},"outputs":[],"source":["def genetic_programming():\n","    return SymbolicRegressor(population_size=10,\n","            generations=5, stopping_criteria=0.85,\n","            p_crossover=0.7, p_subtree_mutation=0.1,\n","            p_hoist_mutation=0.05, p_point_mutation=0.1,\n","            max_samples=0.7, verbose=1,\n","            parsimony_coefficient=1e-4, random_state=42,\n","            function_set=['avg2', 'avg3', 'avg5',\n","                          'median3', 'median5', 'maximum2', 'maximum3', 'maximum5'],\n","            metric='f1-score')"]},{"cell_type":"code","execution_count":16,"metadata":{"id":"yMFnEvVclk0p","executionInfo":{"status":"ok","timestamp":1689158418867,"user_tz":-180,"elapsed":160,"user":{"displayName":"yazan rac","userId":"13751022945634073261"}}},"outputs":[],"source":["def generate_oselm_models(number_of_hidden_neurons, apply_model_replacement=False):\n","    models= [OSELMClassifier(number_of_hidden_neurons, 'relu', binarizer=CustomLabelBinirizer(), random_state=42),\n","             OSELMClassifier(number_of_hidden_neurons, 'relu', binarizer=CustomLabelBinirizer(), random_state=42),\n","             OSELMClassifier(number_of_hidden_neurons, 'relu', binarizer=CustomLabelBinirizer(), random_state=42),\n","             OSELMClassifier(number_of_hidden_neurons, 'relu', binarizer=CustomLabelBinirizer(), random_state=42),\n","             ]\n","\n","    ensemble = Ensemble(classifiers=models, program=genetic_programming(), apply_model_replacement=apply_model_replacement)\n","    return ensemble\n","\n","def generate_ml_models(number_of_hidden_neurons, apply_model_replacement=False):\n","    models = [\n","              KNeighborsClassifier(5),\n","              KNeighborsClassifier(5),\n","              # DecisionTreeClassifier(),\n","              LogisticRegression(),\n","              LogisticRegression(),\n","              GaussianNB(),\n","              GaussianNB(),\n","              GaussianNB(),\n","              ]\n","    ensemble = Ensemble(classifiers=models, program=genetic_programming(), apply_model_replacement=apply_model_replacement)\n","    return ensemble"]},{"cell_type":"code","execution_count":17,"metadata":{"id":"EPZg9p6YzeRa","executionInfo":{"status":"ok","timestamp":1689158418867,"user_tz":-180,"elapsed":157,"user":{"displayName":"yazan rac","userId":"13751022945634073261"}}},"outputs":[],"source":["def concept_drift_detection(drift_detection_obj, sample) -> bool:\n","    \"\"\"\n","    Detect concept drift\n","    :param drift_detection_obj: sklearn drift detection object (ADWIN, DDM, )\n","    :param smaple : new instanece of data stream\n","    return True if concept drift was detected otherwise false\n","    \"\"\"\n","    drift_detection_obj.add_element(sample)\n","    return drift_detection_obj.detected_change()"]},{"cell_type":"code","execution_count":18,"metadata":{"id":"a0HRHwFguFvx","executionInfo":{"status":"ok","timestamp":1689158418885,"user_tz":-180,"elapsed":172,"user":{"displayName":"yazan rac","userId":"13751022945634073261"}}},"outputs":[],"source":["def feature_evolving(evolving_matrix):\n","    \"\"\"\n","    evolving_matrix : list of random list\n","    \"\"\"\n","    random_index = np.random.randint(0, len(evolving_matrix), 1)[0]\n","    return evolving_matrix[random_index]"]},{"cell_type":"code","execution_count":19,"metadata":{"id":"4W42BGI8nLlN","executionInfo":{"status":"ok","timestamp":1689158418886,"user_tz":-180,"elapsed":169,"user":{"displayName":"yazan rac","userId":"13751022945634073261"}}},"outputs":[],"source":["from sklearn.ensemble import RandomForestClassifier\n","from sklearn.feature_selection import SelectFromModel\n","def random_forest_feature_selection(X, y):\n","    \"\"\"\n","    return best feature from X using random forest\n","    \"\"\"\n","    sel = SelectFromModel(RandomForestClassifier(n_estimators = 20))\n","    sel.fit(X, y)\n","    return sel.get_support()"]},{"cell_type":"code","execution_count":20,"metadata":{"id":"ndDkcg0nh3mj","executionInfo":{"status":"ok","timestamp":1689158418888,"user_tz":-180,"elapsed":167,"user":{"displayName":"yazan rac","userId":"13751022945634073261"}}},"outputs":[],"source":["def main(datasets_paths, generate_model, train_size=25, transfer_learning=False, feature_selection=False,apply_model_replacement=False,chunk_number=0):\n","  \"\"\"\n","  datasets_paths: list of paths (absolute path for each dataset)\n","  generate_model: function to generate machine learning model.\n","  train_size: number of samples to be used in training phase.\n","  transfer_learning: to determine using of transfer learning in the training phase.\n","  \"\"\"\n","  # load the dataset and then process it\n","  datasets = {}\n","  for f_name in datasets_paths:\n","      d = prepare_data(f_name)\n","      datasets[f_name.split('/')[-1]] = d\n","  results = {}\n","  ########################################\n","  for key in tqdm(datasets.keys()):\n","\n","      # convert dataset from dataframe to numpy array.\n","      data = datasets[key].values\n","\n","      # split the data into features array and target array.\n","      X, Y = data[:, 0:-1], data[:, -1].astype('int')\n","      model = generate_model(number_of_hidden_neurons=X.shape[1]*3 // 2,apply_model_replacement=apply_model_replacement) # generate_oselm_models\n","\n","      # split the data into chunks (10 chunks)\n","      chunks_features = np.vsplit(X, 10)\n","      chunks_labels = np.split(Y, 10)\n","\n","      results[key] = {}\n","      ################# train on each chunk ####################\n","      print(\"===================== dataset : {} ======================\".format(key))\n","      chunk_number = 1\n","      for chunk_X, chunk_Y in tqdm(zip(chunks_features, chunks_labels)):\n","          if feature_selection:\n","            selected = random_forest_feature_selection(chunk_X, chunk_Y)\n","            unselected_feautres = np.where(selected != 1)[0]\n","          else:\n","            selected = list(range(0, X.shape[1]))\n","            unselected_feautres = None\n","          X_train, X_test, y_train, y_test = chunk_X[:train_size], chunk_X[train_size:], chunk_Y[:train_size], chunk_Y[train_size:]\n","          if transfer_learning:\n","            model, y_pred = train_and_test(model, X_train, y_train, X_test, y_test, unselected_feautres)\n","          else:\n","            _, y_pred = train_and_test(generate_model(number_of_hidden_neurons=X.shape[1]*3 // 2,apply_model_replacement=apply_model_replacement), X_train, y_train, X_test, y_test, unselected_feautres)\n","          results[key][chunk_number] = {\"y_true\" : y_test, \"y_pred\": y_pred}\n","          chunk_number += 1\n","  return results"]},{"cell_type":"code","execution_count":21,"metadata":{"id":"2qndYbimhwnI","executionInfo":{"status":"ok","timestamp":1689158418888,"user_tz":-180,"elapsed":163,"user":{"displayName":"yazan rac","userId":"13751022945634073261"}}},"outputs":[],"source":["# oselm_result = main(filenames, generate_oselm_models, transfer_learning=False)"]},{"cell_type":"code","execution_count":22,"metadata":{"id":"cNktDJzPHj9o","executionInfo":{"status":"ok","timestamp":1689158418889,"user_tz":-180,"elapsed":162,"user":{"displayName":"yazan rac","userId":"13751022945634073261"}}},"outputs":[],"source":["# oselm_result_transfer = main(filenames, generate_oselm_models, transfer_learning=True, feature_selection=False)"]},{"cell_type":"code","execution_count":23,"metadata":{"id":"J42FlZ7aHj6V","executionInfo":{"status":"ok","timestamp":1689158418891,"user_tz":-180,"elapsed":161,"user":{"displayName":"yazan rac","userId":"13751022945634073261"}}},"outputs":[],"source":["# ml_result = main(filenames, generate_ml_models, transfer_learning=False, feature_selection=False)"]},{"cell_type":"code","execution_count":24,"metadata":{"id":"IVRvSCH2SoH6","executionInfo":{"status":"ok","timestamp":1689158418894,"user_tz":-180,"elapsed":160,"user":{"displayName":"yazan rac","userId":"13751022945634073261"}}},"outputs":[],"source":["# oselm_result_transfer_gp = main(filenames, generate_oselm_models, transfer_learning=True, feature_selection=False)"]},{"cell_type":"code","execution_count":25,"metadata":{"id":"lcCfPO12SoE7","executionInfo":{"status":"ok","timestamp":1689158418896,"user_tz":-180,"elapsed":159,"user":{"displayName":"yazan rac","userId":"13751022945634073261"}}},"outputs":[],"source":["# oselm_result_transfer_gp = main(filenames, generate_oselm_models, transfer_learning=True, feature_selection=True)"]},{"cell_type":"code","execution_count":26,"metadata":{"id":"nx-BHuxdo1J2","executionInfo":{"status":"ok","timestamp":1689158418897,"user_tz":-180,"elapsed":156,"user":{"displayName":"yazan rac","userId":"13751022945634073261"}}},"outputs":[],"source":["def E2SC4ID (X,\n","             y,\n","             sample_index:int,\n","             buffer:list,\n","             ensemble: Ensemble,\n","             drift_detection_obj,\n","             maxC=8,\n","             n=2000,\n","             train_size=0.5,\n","             drift=False,\n","             unselected_features=None,\n","             drift_location={}):\n","    \"\"\"\n","    \"\"\"\n","    y_pred = ensemble.global_support_degree(X)\n","\n","    # if the sample is labeled then insert it into buffer\n","    if y is not None:\n","        buffer.append((X, y))\n","        actual_drift = concept_drift_detection(drift_detection_obj, int(y!=y_pred))\n","        if actual_drift and not drift:\n","          drift_location[sample_index] = 'drift'\n","        drift = drift or actual_drift\n","        if len(buffer) >= n:\n","            if drift:\n","                drift = False\n","                drift_detection_obj.reset()\n","                x_buffer, y_buffer = [], []\n","                for tup in buffer:\n","                    x_buffer.append(tup[0])\n","                    y_buffer.append(tup[1])\n","                ######################################################\n","                train_size = int(len(x_buffer)*train_size)\n","                X_train = x_buffer[:train_size]\n","                y_train = y_buffer[:train_size]\n","                X_valid = x_buffer[train_size:]\n","                y_valid = y_buffer[train_size:]\n","                ######################################################\n","                __sum = np.array(y_train).sum()\n","                if 0 ==  __sum or __sum == len(y_train):\n","                  y_train[0] = 0 if y_train[0] == 1 else 1\n","                new_models = ensemble.classifier_induction([\n","                                        model.clf for model in ensemble.classifiers],\n","                                        X_train,\n","                                        y_train,\n","                                        unselected_features)\n","                if len(ensemble.classifiers) > maxC:\n","                    ensemble.model_replacement('time')\n","                ######################################################\n","                ensemble.update_program(X_valid, y_valid)\n","\n","            else:\n","                buffer.clear()\n","        return ensemble, buffer, drift, drift_location"]},{"cell_type":"code","execution_count":27,"metadata":{"id":"bzPNev5QnM6s","executionInfo":{"status":"ok","timestamp":1689158418917,"user_tz":-180,"elapsed":172,"user":{"displayName":"yazan rac","userId":"13751022945634073261"}}},"outputs":[],"source":["def E2SC4ID_STREAM(ensemble, stremdata, y, unselected_features, drift_location, chunk_number):\n","    \"\"\"\n","    \"\"\"\n","    if not ensemble.fitted:\n","      y[0] = 0 if y[0] == 1 else 1\n","      ensemble.fit(stremdata[:200], y[:200])\n","\n","    drift_detection_obj = DDM()\n","    drift = False\n","    buffer = []\n","    for i in tqdm(range(200, len(stremdata))):\n","        X, y_true = stremdata[i], y[i]\n","        ensemble, buffer, drift, drift_location = E2SC4ID (X,\n","                                                           y_true,\n","                                                           sample_index=(i +(chunk_number * 10000)),\n","                                                           buffer=buffer,\n","                                                           ensemble=ensemble,\n","                                                           drift_detection_obj=drift_detection_obj,\n","                                                           maxC=8,\n","                                                           n=2000,\n","                                                           train_size=0.7,\n","                                                           drift=drift,\n","                                                           unselected_features=unselected_features,\n","                                                           drift_location=drift_location)\n","    return ensemble, drift_location"]},{"cell_type":"code","execution_count":28,"metadata":{"id":"Kcy_-pAvPjWY","executionInfo":{"status":"ok","timestamp":1689158418937,"user_tz":-180,"elapsed":190,"user":{"displayName":"yazan rac","userId":"13751022945634073261"}}},"outputs":[],"source":["def save_pickle(obj, file_name):\n","  with open(file_name, 'wb') as f:\n","    pickle.dump(obj, f)\n","def load_pickle(file_name):\n","  with open(file_name, 'rb') as f:\n","    d = pickle.load(f)\n","  return d"]},{"cell_type":"code","execution_count":29,"metadata":{"id":"Ep6MFYsk6tCk","executionInfo":{"status":"ok","timestamp":1689158418939,"user_tz":-180,"elapsed":188,"user":{"displayName":"yazan rac","userId":"13751022945634073261"}}},"outputs":[],"source":["def generate_new_samples(buffer, y_values, n=500, y_col='label'):\n","    if not y_col in buffer.columns.tolist():\n","      y_col = buffer.columns.tolist()[-1]\n","    if y_values.sum() == 0:\n","       return buffer[buffer[y_col] == 1].sample(n, random_state=41)[:, :-1].values, np.array([1] * n)\n","    else:\n","      return buffer[buffer[y_col] == 0].sample(n,random_state=41)[:, :-1].values, np.array([0] * n)"]},{"cell_type":"code","execution_count":30,"metadata":{"id":"DHuWedeLnM3W","executionInfo":{"status":"ok","timestamp":1689158418942,"user_tz":-180,"elapsed":186,"user":{"displayName":"yazan rac","userId":"13751022945634073261"}}},"outputs":[],"source":["def main(f_name, generate_model, train_size=3000,apply_model_replacement=False, transfer_learning=False, feature_selection=\"random_forest\", result_save_path=\"\",ChunkNumber=0):\n","  \"\"\"\n","  datasets_paths: list of paths (absolute path for each dataset)\n","  generate_model: function to generate machine learning model.\n","  train_size: number of samples to be used in training phase.\n","  transfer_learning: to determine using of transfer learning in the training phase.\n","  \"\"\"\n","  # load the dataset and then process it\n","  datasets = {}\n","\n","  d = prepare_data(f_name)\n","  d = d.sample(frac=1, random_state=42)\n","  buffer = d.sample(n=5000)\n","  d.reset_index(inplace=True)\n","  d.replace([np.inf], 0, inplace=True)\n","  datasets[f_name.split('/')[-1]] = d\n","  results = {}\n","  drift_locations_in_all_dataset = {}\n","  ensemble = None ####\n","  ########################################\n","  for key in tqdm(datasets.keys()):\n","      drift_location = {}\n","      results[key] = {'model_result': []}\n","      # convert dataset from dataframe to numpy array.\n","      data = datasets[key].values\n","      # split the data into features array and target array.\n","      X, Y = data[:, 0:-1], data[:, -1].astype('int')\n","      if not os.path.exists(\"{}_evolving_matrix.pkl\".format(key)):\n","        a2 = np.random.randint(low=0, high=X.shape[1], size = X.shape[1] // 6).tolist()\n","        a3 = np.random.randint(low=0, high=X.shape[1], size = X.shape[1] // 5).tolist()\n","        a4 = np.random.randint(low=0, high=X.shape[1], size = X.shape[1] // 4).tolist()\n","        evolving_matrix = [a2, a3, a4]\n","        save_pickle(evolving_matrix, \"{}_evolving_matrix.pkl\".format(key))\n","      else:\n","        evolving_matrix = load_pickle(\"{}_evolving_matrix.pkl\".format(key))\n","      ensemble = generate_model(number_of_hidden_neurons=X.shape[1]*3 // 2, apply_model_replacement=apply_model_replacement)\n","\n","      # split the data into chunks (10 chunks)\n","      chunks_features = np.array_split(X, 10)\n","      chunks_labels = np.array_split(Y, 10)\n","\n","      result_save_path_data = os.path.join(result_save_path, key)\n","      ################# train on each chunk ####################\n","      print(\"===================== dataset : {} ======================\".format(key))\n","      chunk_number = 1\n","      if ChunkNumber>0:\n","        ensemble = load_pickle(os.path.join(result_save_path_data, \"{}_ensemble.pkl\".format(key)))\n","        results = load_pickle(os.path.join(result_save_path_data, \"{}_results.pkl\".format(key)))\n","        drift_locations_in_all_dataset = load_pickle(os.path.join(result_save_path_data, \"{}_drift_locations_in_all_dataset.pkl\".format(key)))\n","      for CN,chunk_X, chunk_Y in tqdm(zip([*range(len(chunks_labels))],chunks_features, chunks_labels)):\n","          if ChunkNumber > CN:\n","            print(\"We Skip Chunk Number : {}\".format(CN))\n","            continue\n","          try:\n","            chunk_X, chunk_Y = SMOTE().fit_resample(chunk_X, chunk_Y)\n","          except:\n","            if chunk_Y.sum() in [0, 1]:\n","              new_samples, new_labels = generate_new_samples(buffer, chunk_Y)\n","              chunk_X = np.concatenate((chunk_X, new_samples))\n","              chunk_Y = np.concatenate((chunk_Y, new_labels))\n","          gc.collect()\n","          unselected_feautres = None\n","          selected = None\n","          if feature_selection[0] == \"feature_evolving\":\n","            unselected_feautres = feature_evolving(evolving_matrix=evolving_matrix)\n","            chunk_X = np.delete(chunk_X, unselected_feautres, 1)\n","            if feature_selection[1] == \"random_forest\":\n","              selected = random_forest_feature_selection(chunk_X, chunk_Y)\n","              unselected_feautres = np.where(selected != 1)[0]\n","            elif feature_selection[1] == \"DFS_feature_selection\":\n","              selected = dynamic_feature_selection(chunk_X, chunk_Y)\n","              unselected_feautres = np.where(selected != 1)[0]\n","          else:\n","            if feature_selection[1] == \"random_forest\":\n","              selected = random_forest_feature_selection(chunk_X, chunk_Y)\n","              unselected_feautres = np.where(selected != 1)[0]\n","            elif feature_selection[1] == \"DFS_feature_selection\":\n","              selected = dynamic_feature_selection(chunk_X, chunk_Y)\n","              unselected_feautres = np.where(selected != 1)[0]\n","\n","          X_train, X_test, y_train, y_test = chunk_X[:train_size], chunk_X[train_size:], chunk_Y[:train_size], chunk_Y[train_size:]\n","          if transfer_learning:\n","            temp = np.squeeze(X_train[:, selected]) if len(list(X_train[:, selected].shape))>2 else X_train[:, selected]\n","            ensemble, drift_location = E2SC4ID_STREAM(ensemble, temp, y_train, None, drift_location, chunk_number)\n","            temp = np.squeeze(X_test[:, selected]) if len(list(X_test[:, selected].shape))>2 else X_test[:, selected]\n","            ensemble.evaluate(temp, y_test, chunk_number)\n","          else:\n","            ensemble, drift_location = E2SC4ID_STREAM(generate_model(number_of_hidden_neurons=X.shape[1]*3 // 2,apply_model_replacement=apply_model_replacement),\n","                                                      X_train, y_train, unselected_feautres, drift_location, chunk_number)\n","            ensemble.evaluate(X_test, y_test, chunk_number)\n","\n","          temp = np.squeeze(X_test[:, selected]) if len(list(X_test[:, selected].shape))>2 else X_test[:, selected]\n","          y_pre = ensemble.predict(temp)\n","          results[key][chunk_number] = {\"y_true\" : y_test, \"y_pred\": y_pre}\n","          results[key]['model_result'].append(ensemble.scores)\n","          if transfer_learning:\n","             ensemble.fit(temp, y_test, None)\n","          chunk_number += 1\n","          drift_locations_in_all_dataset[key] = drift_location\n","          if not os.path.exists(result_save_path_data):\n","            os.mkdir(result_save_path_data)\n","          save_pickle(ensemble, os.path.join(result_save_path_data, \"{}_ensemble.pkl\".format(key)))\n","          save_pickle(results, os.path.join(result_save_path_data, \"{}_results.pkl\".format(key)))\n","          save_pickle(drift_locations_in_all_dataset, os.path.join(result_save_path_data, \"{}_drift_locations_in_all_dataset.pkl\".format(key)))\n","  return ensemble, results, drift_locations_in_all_dataset"]},{"cell_type":"markdown","metadata":{"id":"kK4kg3wuunvt"},"source":["# without feature evolving ,with random_forest"]},{"cell_type":"code","execution_count":31,"metadata":{"id":"0C32roc-7Aox","executionInfo":{"status":"ok","timestamp":1689158418945,"user_tz":-180,"elapsed":184,"user":{"displayName":"yazan rac","userId":"13751022945634073261"}}},"outputs":[],"source":["# # is done\n","# use_know = False\n","# set_use_know(use_know)\n","# path = os.path.join(results_path,'gp_combiner_with_model_replacement_random_forest')\n","# os.makedirs(path, exist_ok=True)\n","# for i,f_name in enumerate(filenames):\n","#     oselm_model_no_transfer, oselm_result_no_transfer, drift_locations_in_all_dataset_ = main(f_name, generate_oselm_models, apply_model_replacement=True,\n","#                                                                                               transfer_learning=False, feature_selection=[\"with_out_feature_evolving\",'random_forest'], result_save_path=path)"]},{"cell_type":"code","execution_count":31,"metadata":{"id":"-zK2zdleHPwG","executionInfo":{"status":"ok","timestamp":1689158418959,"user_tz":-180,"elapsed":197,"user":{"displayName":"yazan rac","userId":"13751022945634073261"}}},"outputs":[],"source":[]},{"cell_type":"code","execution_count":32,"metadata":{"id":"yoYj4Xx77Aox","executionInfo":{"status":"ok","timestamp":1689158418961,"user_tz":-180,"elapsed":180,"user":{"displayName":"yazan rac","userId":"13751022945634073261"}}},"outputs":[],"source":["# # is running\n","# # ChunkNumber = 0\n","# use_know = False\n","# set_use_know(use_know)\n","# path = os.path.join(results_path,'faoselm_gp_combiner_with_model_replacement_random_forest')\n","# os.makedirs(path, exist_ok=True)\n","# for f_name in [filenames[0]]:\n","#   faoselm_result_transfer, faoselm_result_transfer_result, drift_locations_in_all_dataset_1 = main(f_name, generate_oselm_models, apply_model_replacement=True,\n","#                                                                                                    transfer_learning=True, feature_selection=[\"with_out_feature_evolving\",'random_forest'], result_save_path=path)"]},{"cell_type":"code","execution_count":33,"metadata":{"executionInfo":{"elapsed":179,"status":"ok","timestamp":1689158418963,"user":{"displayName":"yazan rac","userId":"13751022945634073261"},"user_tz":-180},"id":"BDuOSBKbHQdL"},"outputs":[],"source":["# # is running\n","# use_know = False\n","# set_use_know(use_know)\n","# path = os.path.join(results_path,'faoselm_gp_combiner_with_model_replacement_random_forest')\n","# os.makedirs(path, exist_ok=True)\n","# for f_name in [filenames[1]]:\n","#   faoselm_result_transfer, faoselm_result_transfer_result, drift_locations_in_all_dataset_1 = main(f_name, generate_oselm_models, apply_model_replacement=True,\n","#                                                                                                    transfer_learning=True, feature_selection=[\"with_out_feature_evolving\",'random_forest'], result_save_path=path,ChunkNumber=9)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"WH-liaBgHSzV","outputId":"58d2220d-1e02-42a2-ad34-a827ce0fb14d"},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"1ec09c2b532f4fb09683b9be1f4a82f4","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/1 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["===================== dataset : CSE-CIC2018.csv ======================\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"bfa2e77903fd428e8bce96e2b1f16f8b","version_major":2,"version_minor":0},"text/plain":["0it [00:00, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["We Skip Chunk Number : 0\n","We Skip Chunk Number : 1\n","We Skip Chunk Number : 2\n","We Skip Chunk Number : 3\n","We Skip Chunk Number : 4\n","We Skip Chunk Number : 5\n","We Skip Chunk Number : 6\n","We Skip Chunk Number : 7\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"6f28ab72e1a348b294effbf67c4d35a8","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/2800 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"}],"source":["# is not running\n","use_know = False\n","set_use_know(use_know)\n","path = os.path.join(results_path,'faoselm_gp_combiner_with_model_replacement_random_forest')\n","os.makedirs(path, exist_ok=True)\n","for f_name in [filenames[2]]:\n","  faoselm_result_transfer, faoselm_result_transfer_result, drift_locations_in_all_dataset_1 = main(f_name, generate_oselm_models, apply_model_replacement=True,\n","                                                                                                   transfer_learning=True, feature_selection=[\"with_out_feature_evolving\",'random_forest'], result_save_path=path,ChunkNumber=8)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"C4HCmvMnHS2O"},"outputs":[],"source":["# is not running\n","use_know = False\n","set_use_know(use_know)\n","path = os.path.join(results_path,'faoselm_gp_combiner_with_model_replacement_random_forest')\n","os.makedirs(path, exist_ok=True)\n","for f_name in [filenames[3]]:\n","  faoselm_result_transfer, faoselm_result_transfer_result, drift_locations_in_all_dataset_1 = main(f_name, generate_oselm_models, apply_model_replacement=True,\n","                                                                                                   transfer_learning=True, feature_selection=[\"with_out_feature_evolving\",'random_forest'], result_save_path=path)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jbswP7fVHS4C"},"outputs":[],"source":["# is not running\n","use_know = False\n","set_use_know(use_know)\n","path = os.path.join(results_path,'faoselm_gp_combiner_with_model_replacement_random_forest')\n","os.makedirs(path, exist_ok=True)\n","for f_name in [filenames[4]]:\n","  faoselm_result_transfer, faoselm_result_transfer_result, drift_locations_in_all_dataset_1 = main(f_name, generate_oselm_models, apply_model_replacement=True,\n","                                                                                                   transfer_learning=True, feature_selection=[\"with_out_feature_evolving\",'random_forest'], result_save_path=path)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-Mfwtz0iHS7a"},"outputs":[],"source":["# is not running\n","use_know = False\n","set_use_know(use_know)\n","path = os.path.join(results_path,'faoselm_gp_combiner_with_model_replacement_random_forest')\n","os.makedirs(path, exist_ok=True)\n","for f_name in [filenames[5]]:\n","  faoselm_result_transfer, faoselm_result_transfer_result, drift_locations_in_all_dataset_1 = main(f_name, generate_oselm_models, apply_model_replacement=True,\n","                                                                                                   transfer_learning=True, feature_selection=[\"with_out_feature_evolving\",'random_forest'], result_save_path=path)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"42LjyEfrHTBE"},"outputs":[],"source":["# is not running\n","use_know = False\n","set_use_know(use_know)\n","path = os.path.join(results_path,'faoselm_gp_combiner_with_model_replacement_random_forest')\n","os.makedirs(path, exist_ok=True)\n","for f_name in [filenames[6]]:\n","  faoselm_result_transfer, faoselm_result_transfer_result, drift_locations_in_all_dataset_1 = main(f_name, generate_oselm_models, apply_model_replacement=True,\n","                                                                                                   transfer_learning=True, feature_selection=[\"with_out_feature_evolving\",'random_forest'], result_save_path=path)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"D6KsEtJDHTDJ"},"outputs":[],"source":["# is not running\n","use_know = False\n","set_use_know(use_know)\n","path = os.path.join(results_path,'faoselm_gp_combiner_with_model_replacement_random_forest')\n","os.makedirs(path, exist_ok=True)\n","for f_name in [filenames[7]]:\n","  faoselm_result_transfer, faoselm_result_transfer_result, drift_locations_in_all_dataset_1 = main(f_name, generate_oselm_models, apply_model_replacement=True,\n","                                                                                                   transfer_learning=True, feature_selection=[\"with_out_feature_evolving\",'random_forest'], result_save_path=path)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6MdGNljXIy4R"},"outputs":[],"source":["# is not running\n","use_know = False\n","set_use_know(use_know)\n","path = os.path.join(results_path,'faoselm_gp_combiner_with_model_replacement_random_forest')\n","os.makedirs(path, exist_ok=True)\n","for f_name in [filenames[8]]:\n","  faoselm_result_transfer, faoselm_result_transfer_result, drift_locations_in_all_dataset_1 = main(f_name, generate_oselm_models, apply_model_replacement=True,\n","                                                                                                   transfer_learning=True, feature_selection=[\"with_out_feature_evolving\",'random_forest'], result_save_path=path)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7yLbixv-HTGk"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"B5JWl6aU7Aox"},"outputs":[],"source":["# is not running\n","use_know = True\n","set_use_know(use_know)\n","path = os.path.join(results_path,'kpfaoselm_gp_combiner_with_model_replacement_random_forest')\n","os.makedirs(path, exist_ok=True)\n","for f_name in [filenames[0]]:\n","  faoselm_result_transfer, faoselm_result_transfer_result, drift_locations_in_all_dataset_1 = main(f_name, generate_oselm_models, apply_model_replacement=True,\n","                                                                                                   transfer_learning=True, feature_selection=[\"with_out_feature_evolving\",'random_forest'], result_save_path=path)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"bbTk66_BI7rx"},"outputs":[],"source":["# is not running\n","use_know = True\n","set_use_know(use_know)\n","path = os.path.join(results_path,'kpfaoselm_gp_combiner_with_model_replacement_random_forest')\n","os.makedirs(path, exist_ok=True)\n","for f_name in [filenames[1]]:\n","  faoselm_result_transfer, faoselm_result_transfer_result, drift_locations_in_all_dataset_1 = main(f_name, generate_oselm_models, apply_model_replacement=True,\n","                                                                                                   transfer_learning=True, feature_selection=[\"with_out_feature_evolving\",'random_forest'], result_save_path=path)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"VFvml6cwI7uy"},"outputs":[],"source":["# is not running\n","use_know = True\n","set_use_know(use_know)\n","path = os.path.join(results_path,'kpfaoselm_gp_combiner_with_model_replacement_random_forest')\n","os.makedirs(path, exist_ok=True)\n","for f_name in [filenames[2]]:\n","  faoselm_result_transfer, faoselm_result_transfer_result, drift_locations_in_all_dataset_1 = main(f_name, generate_oselm_models, apply_model_replacement=True,\n","                                                                                                   transfer_learning=True, feature_selection=[\"with_out_feature_evolving\",'random_forest'], result_save_path=path)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3qKWVXIzI7xa"},"outputs":[],"source":["# is not running\n","use_know = True\n","set_use_know(use_know)\n","path = os.path.join(results_path,'kpfaoselm_gp_combiner_with_model_replacement_random_forest')\n","os.makedirs(path, exist_ok=True)\n","for f_name in [filenames[3]]:\n","  faoselm_result_transfer, faoselm_result_transfer_result, drift_locations_in_all_dataset_1 = main(f_name, generate_oselm_models, apply_model_replacement=True,\n","                                                                                                   transfer_learning=True, feature_selection=[\"with_out_feature_evolving\",'random_forest'], result_save_path=path)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"re6ii3doI7zt"},"outputs":[],"source":["# is not running\n","use_know = True\n","set_use_know(use_know)\n","path = os.path.join(results_path,'kpfaoselm_gp_combiner_with_model_replacement_random_forest')\n","os.makedirs(path, exist_ok=True)\n","for f_name in [filenames[4]]:\n","  faoselm_result_transfer, faoselm_result_transfer_result, drift_locations_in_all_dataset_1 = main(f_name, generate_oselm_models, apply_model_replacement=True,\n","                                                                                                   transfer_learning=True, feature_selection=[\"with_out_feature_evolving\",'random_forest'], result_save_path=path)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"iRkvauvrI72M"},"outputs":[],"source":["# is not running\n","use_know = True\n","set_use_know(use_know)\n","path = os.path.join(results_path,'kpfaoselm_gp_combiner_with_model_replacement_random_forest')\n","os.makedirs(path, exist_ok=True)\n","for f_name in [filenames[5]]:\n","  faoselm_result_transfer, faoselm_result_transfer_result, drift_locations_in_all_dataset_1 = main(f_name, generate_oselm_models, apply_model_replacement=True,\n","                                                                                                   transfer_learning=True, feature_selection=[\"with_out_feature_evolving\",'random_forest'], result_save_path=path)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Adh_0jDEI740"},"outputs":[],"source":["# is not running\n","use_know = True\n","set_use_know(use_know)\n","path = os.path.join(results_path,'kpfaoselm_gp_combiner_with_model_replacement_random_forest')\n","os.makedirs(path, exist_ok=True)\n","for f_name in [filenames[6]]:\n","  faoselm_result_transfer, faoselm_result_transfer_result, drift_locations_in_all_dataset_1 = main(f_name, generate_oselm_models, apply_model_replacement=True,\n","                                                                                                   transfer_learning=True, feature_selection=[\"with_out_feature_evolving\",'random_forest'], result_save_path=path)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"XIjOwuYJI78F"},"outputs":[],"source":["# is not running\n","use_know = True\n","set_use_know(use_know)\n","path = os.path.join(results_path,'kpfaoselm_gp_combiner_with_model_replacement_random_forest')\n","os.makedirs(path, exist_ok=True)\n","for f_name in [filenames[7]]:\n","  faoselm_result_transfer, faoselm_result_transfer_result, drift_locations_in_all_dataset_1 = main(f_name, generate_oselm_models, apply_model_replacement=True,\n","                                                                                                   transfer_learning=True, feature_selection=[\"with_out_feature_evolving\",'random_forest'], result_save_path=path)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qWp3AkGUJMTv"},"outputs":[],"source":["# is not running\n","use_know = True\n","set_use_know(use_know)\n","path = os.path.join(results_path,'kpfaoselm_gp_combiner_with_model_replacement_random_forest')\n","os.makedirs(path, exist_ok=True)\n","for f_name in [filenames[8]]:\n","  faoselm_result_transfer, faoselm_result_transfer_result, drift_locations_in_all_dataset_1 = main(f_name, generate_oselm_models, apply_model_replacement=True,\n","                                                                                                   transfer_learning=True, feature_selection=[\"with_out_feature_evolving\",'random_forest'], result_save_path=path)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ORsK5f5FHRZu"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"SPZsUxDi7Aoy"},"outputs":[],"source":["# is not running\n","use_know = False\n","set_use_know(use_know)\n","path = os.path.join(results_path,'ml_gp_combiner_with_model_replacement_random_forest')\n","os.makedirs(path, exist_ok=True)\n","for f_name in [filenames[0]]:\n","  ml_result_transfer, ml_result_transfer_result, drift_locations_in_all_dataset_4 = main(f_name, generate_ml_models, apply_model_replacement=True,\n","                                                                                                   transfer_learning=False, feature_selection=[\"with_out_feature_evolving\",'random_forest'], result_save_path=path)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"EhOUas4pJUey"},"outputs":[],"source":["# is not running\n","use_know = False\n","set_use_know(use_know)\n","path = os.path.join(results_path,'ml_gp_combiner_with_model_replacement_random_forest')\n","os.makedirs(path, exist_ok=True)\n","for f_name in [filenames[1]]:\n","  ml_result_transfer, ml_result_transfer_result, drift_locations_in_all_dataset_4 = main(f_name, generate_ml_models, apply_model_replacement=True,\n","                                                                                                   transfer_learning=False, feature_selection=[\"with_out_feature_evolving\",'random_forest'], result_save_path=path)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Rq8phwqPJUg9"},"outputs":[],"source":["# is not running\n","use_know = False\n","set_use_know(use_know)\n","path = os.path.join(results_path,'ml_gp_combiner_with_model_replacement_random_forest')\n","os.makedirs(path, exist_ok=True)\n","for f_name in [filenames[2]]:\n","  ml_result_transfer, ml_result_transfer_result, drift_locations_in_all_dataset_4 = main(f_name, generate_ml_models, apply_model_replacement=True,\n","                                                                                                   transfer_learning=False, feature_selection=[\"with_out_feature_evolving\",'random_forest'], result_save_path=path)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ElaA9ijmJUjp"},"outputs":[],"source":["# is not running\n","use_know = False\n","set_use_know(use_know)\n","path = os.path.join(results_path,'ml_gp_combiner_with_model_replacement_random_forest')\n","os.makedirs(path, exist_ok=True)\n","for f_name in [filenames[3]]:\n","  ml_result_transfer, ml_result_transfer_result, drift_locations_in_all_dataset_4 = main(f_name, generate_ml_models, apply_model_replacement=True,\n","                                                                                                   transfer_learning=False, feature_selection=[\"with_out_feature_evolving\",'random_forest'], result_save_path=path)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"t3GOX27pJUmN"},"outputs":[],"source":["# is not running\n","use_know = False\n","set_use_know(use_know)\n","path = os.path.join(results_path,'ml_gp_combiner_with_model_replacement_random_forest')\n","os.makedirs(path, exist_ok=True)\n","for f_name in [filenames[4]]:\n","  ml_result_transfer, ml_result_transfer_result, drift_locations_in_all_dataset_4 = main(f_name, generate_ml_models, apply_model_replacement=True,\n","                                                                                                   transfer_learning=False, feature_selection=[\"with_out_feature_evolving\",'random_forest'], result_save_path=path)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"SIoV5Br7JUom"},"outputs":[],"source":["# is not running\n","use_know = False\n","set_use_know(use_know)\n","path = os.path.join(results_path,'ml_gp_combiner_with_model_replacement_random_forest')\n","os.makedirs(path, exist_ok=True)\n","for f_name in [filenames[5]]:\n","  ml_result_transfer, ml_result_transfer_result, drift_locations_in_all_dataset_4 = main(f_name, generate_ml_models, apply_model_replacement=True,\n","                                                                                                   transfer_learning=False, feature_selection=[\"with_out_feature_evolving\",'random_forest'], result_save_path=path)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"tX-OaA95JU8E"},"outputs":[],"source":["# is not running\n","use_know = False\n","set_use_know(use_know)\n","path = os.path.join(results_path,'ml_gp_combiner_with_model_replacement_random_forest')\n","os.makedirs(path, exist_ok=True)\n","for f_name in [filenames[6]]:\n","  ml_result_transfer, ml_result_transfer_result, drift_locations_in_all_dataset_4 = main(f_name, generate_ml_models, apply_model_replacement=True,\n","                                                                                                   transfer_learning=False, feature_selection=[\"with_out_feature_evolving\",'random_forest'], result_save_path=path)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"NYrTZ2CAJU-R"},"outputs":[],"source":["# is not running\n","use_know = False\n","set_use_know(use_know)\n","path = os.path.join(results_path,'ml_gp_combiner_with_model_replacement_random_forest')\n","os.makedirs(path, exist_ok=True)\n","for f_name in [filenames[7]]:\n","  ml_result_transfer, ml_result_transfer_result, drift_locations_in_all_dataset_4 = main(f_name, generate_ml_models, apply_model_replacement=True,\n","                                                                                                   transfer_learning=False, feature_selection=[\"with_out_feature_evolving\",'random_forest'], result_save_path=path)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"QoC6nFvsJhvJ"},"outputs":[],"source":["# is not running\n","use_know = False\n","set_use_know(use_know)\n","path = os.path.join(results_path,'ml_gp_combiner_with_model_replacement_random_forest')\n","os.makedirs(path, exist_ok=True)\n","for f_name in [filenames[8]]:\n","  ml_result_transfer, ml_result_transfer_result, drift_locations_in_all_dataset_4 = main(f_name, generate_ml_models, apply_model_replacement=True,\n","                                                                                                   transfer_learning=False, feature_selection=[\"with_out_feature_evolving\",'random_forest'], result_save_path=path)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"tfNnsdlnGa7l"},"outputs":[],"source":[]}],"metadata":{"accelerator":"GPU","colab":{"machine_shape":"hm","provenance":[]},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}